{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Book\n",
    "\n",
    "### 1. Introduction\n",
    "**Deep learning**: building complicated concepts from simple ones - the hierarchical graph is deep.\n",
    "\n",
    "Knowledge base approach vs machine learning approach (AI systems acquire their own knowledge, by extracting patterns in raw data).\n",
    "\n",
    "**Features and Representation**: we provide simple ML algorithms a good representation (collection of features) of the independent variable. Like providing area of an apartment instead of pictures of it to a price estimator.\n",
    "\n",
    "**Representation learning**: not only learn the mapping from representation to output, but also the representation itself.\n",
    "\n",
    "**Autoencoder**: encoder function converts input data into a different representation, decoder function converts new representation back to the original format.\n",
    "\n",
    "In feature selection, we want to seperate **factors of variation** that explains the observed data. These may be unobserved or imagined. It can be hard to disentangle these factors of variation from the raw data.\n",
    "\n",
    "**Deep learning** helps address this central problem in representation learning by introducing representations that are expressed in terms of other, simpler representations.\n",
    "\n",
    "#### 1.21 Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## I Applied Math and Machine Learning Basics\n",
    "### 2. Linear Algebra\n",
    "\n",
    "\n",
    "### 3. Probability and Information Theory\n",
    "\n",
    "\n",
    "### 4. Numeric Computation\n",
    "\n",
    "\n",
    "### 5. Machine Learning Basics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Deep Networks\n",
    "### 6. Deep Feedforward Networks\n",
    "\n",
    "\n",
    "### 7. Regularization for Deep Learning\n",
    "\n",
    "\n",
    "### 8. Optimization for Training Deep Models\n",
    "\n",
    "\n",
    "### 9. Convolutional Networks\n",
    "\n",
    "\n",
    "### 10. Sequence Modeling: Recurrent and Recursive Nets\n",
    "\n",
    "\n",
    "### 11. Practical Methodology\n",
    "\n",
    "\n",
    "### 12. Applications\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III Deep Learning Research\n",
    "### 13. Linear Factor Models\n",
    "\n",
    "\n",
    "### 14. Autoencoders\n",
    "\n",
    "\n",
    "### 15. Representation Learning\n",
    "\n",
    "\n",
    "### 16. Structured Probabilistic Models for Deep Learning\n",
    "\n",
    "\n",
    "### 17. Monte Carlo Methods\n",
    "\n",
    "\n",
    "### 18. Confronting the Partition Function\n",
    "\n",
    "\n",
    "### 19. Approximate Inference\n",
    "\n",
    "\n",
    "### 20. Deep Generative Models\n",
    "\n",
    "## "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
