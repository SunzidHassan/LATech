{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "### Working with data\n",
    "PyTorch has two primitives to work with data: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch offers domain-specific libraries such as\n",
    "[TorchText](https://pytorch.org/text/stable/index.html),\n",
    "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
    "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
    "include datasets. For this tutorial, we will be using a TorchVision\n",
    "dataset.\n",
    "\n",
    "The `torchvision.datasets` module contains `Dataset` objects for many\n",
    "real-world vision data like CIFAR, COCO ([full list\n",
    "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
    "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
    "includes two arguments: `transform` and `target_transform` to modify the\n",
    "samples and labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:03<00:00, 7967741.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 209638.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:06<00:00, 681541.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 5331426.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
    "iterable over our dataset, and supports automatic batching, sampling,\n",
    "shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Models\n",
    "\n",
    "To define a neural network in PyTorch, we create a class that inherits from [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "We define the layers of the network in the `__init__` function and\n",
    "specify how data will pass through the network in the `forward`\n",
    "function. To accelerate operations in the neural network, we move it to the GPU or MPS if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stak): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training\n",
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "          else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stak = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stak(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Model Parameters\n",
    "To train a model, we need a [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an [optimizer](https://pytorch.org/docs/stable/optim.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model\\'s parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the model\\'s performance against the test dataset to\n",
    "ensure it is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (*epochs*).\n",
    "During each epoch, the model learns parameters to make better\n",
    "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
    "we\\'d like to see the accuracy increase and the loss decrease with every\n",
    "epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.312702 [   64/60000]\n",
      "loss: 2.302686 [ 6464/60000]\n",
      "loss: 2.273867 [12864/60000]\n",
      "loss: 2.261350 [19264/60000]\n",
      "loss: 2.255846 [25664/60000]\n",
      "loss: 2.224161 [32064/60000]\n",
      "loss: 2.225834 [38464/60000]\n",
      "loss: 2.197489 [44864/60000]\n",
      "loss: 2.193152 [51264/60000]\n",
      "loss: 2.153397 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 2.156094 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.177377 [   64/60000]\n",
      "loss: 2.168272 [ 6464/60000]\n",
      "loss: 2.102842 [12864/60000]\n",
      "loss: 2.112488 [19264/60000]\n",
      "loss: 2.071274 [25664/60000]\n",
      "loss: 2.012736 [32064/60000]\n",
      "loss: 2.037289 [38464/60000]\n",
      "loss: 1.961162 [44864/60000]\n",
      "loss: 1.961603 [51264/60000]\n",
      "loss: 1.890148 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.888956 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.933108 [   64/60000]\n",
      "loss: 1.903405 [ 6464/60000]\n",
      "loss: 1.777747 [12864/60000]\n",
      "loss: 1.816611 [19264/60000]\n",
      "loss: 1.707883 [25664/60000]\n",
      "loss: 1.663428 [32064/60000]\n",
      "loss: 1.687826 [38464/60000]\n",
      "loss: 1.583306 [44864/60000]\n",
      "loss: 1.600447 [51264/60000]\n",
      "loss: 1.512663 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 1.520416 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.592987 [   64/60000]\n",
      "loss: 1.558250 [ 6464/60000]\n",
      "loss: 1.399751 [12864/60000]\n",
      "loss: 1.478368 [19264/60000]\n",
      "loss: 1.357630 [25664/60000]\n",
      "loss: 1.355151 [32064/60000]\n",
      "loss: 1.377433 [38464/60000]\n",
      "loss: 1.292554 [44864/60000]\n",
      "loss: 1.316011 [51264/60000]\n",
      "loss: 1.243372 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.257951 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.335883 [   64/60000]\n",
      "loss: 1.318885 [ 6464/60000]\n",
      "loss: 1.147334 [12864/60000]\n",
      "loss: 1.260105 [19264/60000]\n",
      "loss: 1.136152 [25664/60000]\n",
      "loss: 1.160153 [32064/60000]\n",
      "loss: 1.187607 [38464/60000]\n",
      "loss: 1.116233 [44864/60000]\n",
      "loss: 1.141249 [51264/60000]\n",
      "loss: 1.084426 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.095398 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models\n",
    "A common way to save a model is to serialize the internal state\n",
    "dictionary (containing the model parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models\n",
    "The process for loading a model includes re-creating the model structure and loading the state dictionary into it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "Like array, but can run on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Tensor\n",
    "Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "print(data)\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From numpy array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From another tensor**, new tensor keep shape and datatype of old tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[0.2128, 0.8975],\n",
      "        [0.8850, 0.3905]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides dtype\n",
    "print(f\"Ones Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With random or constant values:**\n",
    "\n",
    "`shape` is a tuple of tensor dimensions. In the functions below, it\n",
    "determines the dimensionality of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5674, 0.6799, 0.2115],\n",
      "        [0.6086, 0.1519, 0.2078]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes of a Tensor\n",
    "\n",
    "Tensor attributes describe their shape, datatype, and the device on\n",
    "which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([0.8542, 0.7970, 0.1524, 0.4318])\n",
      "First column: tensor([0.8542, 0.9904, 0.2437, 0.6107])\n",
      "Last column: tensor([0.4318, 0.7757, 0.8978, 0.2656])\n",
      "tensor([[0.8542, 0.0000, 0.1524, 0.4318],\n",
      "        [0.9904, 0.0000, 0.5376, 0.7757],\n",
      "        [0.2437, 0.0000, 0.2167, 0.8978],\n",
      "        [0.6107, 0.0000, 0.6186, 0.2656]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "print(f\"First row: {tensor[0, :]}\")\n",
    "print(f\"First column: {tensor[:,0]}\")\n",
    "print(f\"Last column: {tensor[...,-1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joining tensors** `torch.cat` to concatenate tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8542, 0.0000, 0.1524, 0.4318, 0.8542, 0.0000, 0.1524, 0.4318, 0.8542,\n",
      "         0.0000, 0.1524, 0.4318],\n",
      "        [0.9904, 0.0000, 0.5376, 0.7757, 0.9904, 0.0000, 0.5376, 0.7757, 0.9904,\n",
      "         0.0000, 0.5376, 0.7757],\n",
      "        [0.2437, 0.0000, 0.2167, 0.8978, 0.2437, 0.0000, 0.2167, 0.8978, 0.2437,\n",
      "         0.0000, 0.2167, 0.8978],\n",
      "        [0.6107, 0.0000, 0.6186, 0.2656, 0.6107, 0.0000, 0.6186, 0.2656, 0.6107,\n",
      "         0.0000, 0.6186, 0.2656]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arithmatic operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single-element tensors** If you have a one-element tensor, for example\n",
    "by aggregating all values of a tensor into one value, you can convert it\n",
    "to a Python numerical value using `item()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-place operations** Operations that store the result into the\n",
    "operand are called in-place. They are denoted by a `_` suffix. For\n",
    "example: `x.copy_(y)`, `x.t_()`, will change `x`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge with numpy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
    "locations, and changing one will change the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor to NumPy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders\n",
    "\n",
    "Code for processing data samples can get messy and hard to maintain; we\n",
    "ideally want our dataset code to be decoupled from our model training\n",
    "code for better readability and modularity. PyTorch provides two data\n",
    "primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset`\n",
    "that allow you to use pre-loaded datasets as well as your own data.\n",
    "`Dataset` stores the samples and their corresponding labels, and\n",
    "`DataLoader` wraps an iterable around the `Dataset` to enable easy\n",
    "access to the samples.\n",
    "\n",
    "PyTorch domain libraries provide a number of pre-loaded datasets (such\n",
    "as FashionMNIST) that subclass `torch.utils.data.Dataset` and implement\n",
    "functions specific to the particular data. They can be used to prototype\n",
    "and benchmark your model. You can find them here: [Image\n",
    "Datasets](https://pytorch.org/vision/stable/datasets.html), [Text\n",
    "Datasets](https://pytorch.org/text/stable/datasets.html), and [Audio\n",
    "Datasets](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "### Loading a Dataset\n",
    "Here is an example of how to load the\n",
    "[Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist/)\n",
    "dataset from TorchVision. Fashion-MNIST is a dataset of Zalando's\n",
    "article images consisting of 60,000 training examples and 10,000 test\n",
    "examples. Each example comprises a 28×28 grayscale image and an\n",
    "associated label from one of 10 classes.\n",
    "\n",
    "We load the [FashionMNIST Dataset](https://pytorch.org/vision/stable/datasets.html#fashion-mnist) with the following parameters:\n",
    "\n",
    ":   -   `root` is the path where the train/test data is stored,\n",
    "    -   `train` specifies training or test dataset,\n",
    "    -   `download=True` downloads the data from the internet if it\\'s\n",
    "        not available at `root`.\n",
    "    -   `transform` and `target_transform` specify the feature and label\n",
    "        transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating and Visualizing the Dataset\n",
    "\n",
    "We can index `Datasets` manually like a list: `training_data[index]`. We\n",
    "use `matplotlib` to visualize some samples in our training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Dataset for your files\n",
    "\n",
    "A custom Dataset class must implement three functions:\n",
    "[\\_\\_init\\_\\_]{.title-ref}, [\\_\\_len\\_\\_]{.title-ref}, and\n",
    "[\\_\\_getitem\\_\\_]{.title-ref}. Take a look at this implementation; the\n",
    "FashionMNIST images are stored in a directory `img_dir`, and their\n",
    "labels are stored separately in a CSV file `annotations_file`.\n",
    "\n",
    "In the next sections, we\\'ll break down what\\'s happening in each of\n",
    "these functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`__init__`\n",
    "\n",
    "The \\_\\_[init]() function is run once when instantiating the Dataset\n",
    "object. We initialize the directory containing the images, the\n",
    "annotations file, and both transforms (covered in more detail in the\n",
    "next section).\n",
    "\n",
    "The labels.csv file looks like: :\n",
    "\n",
    "    tshirt1.jpg, 0\n",
    "    tshirt2.jpg, 0\n",
    "    ......\n",
    "    ankleboot999.jpg, 9\n",
    "\n",
    "`__len__`\n",
    "\n",
    "The \\_\\_[len]() function returns the number of samples in our dataset.\n",
    "\n",
    "`__getitem__`\n",
    "\n",
    "The \\_\\_[getitem]() function loads and returns a sample from the dataset\n",
    "at the given index `idx`. Based on the index, it identifies the image\\'s\n",
    "location on disk, converts that to a tensor using `read_image`,\n",
    "retrieves the corresponding label from the csv data in\n",
    "`self.img_labels`, calls the transform functions on them (if\n",
    "applicable), and returns the tensor image and corresponding label in a\n",
    "tuple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing your data for training with DataLoaders\n",
    "\n",
    "The `Dataset` retrieves our dataset\\'s features and labels one sample at\n",
    "a time. While training a model, we typically want to pass samples in\n",
    "\\\"minibatches\\\", reshuffle the data at every epoch to reduce model\n",
    "overfitting, and use Python\\'s `multiprocessing` to speed up data\n",
    "retrieval.\n",
    "\n",
    "`DataLoader` is an iterable that abstracts this complexity for us in an\n",
    "easy API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the DataLoader\n",
    "\n",
    "We have loaded that dataset into the `DataLoader` and can iterate\n",
    "through the dataset as needed. Each iteration below returns a batch of\n",
    "`train_features` and `train_labels` (containing `batch_size=64` features\n",
    "and labels respectively). Because we specified `shuffle=True`, after we\n",
    "iterate over all batches the data is shuffled (for finer-grained control\n",
    "over the data loading order, take a look at\n",
    "[Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "\n",
    "Data does not always come in its final processed form that is required\n",
    "for training machine learning algorithms. We use **transforms** to\n",
    "perform some manipulation of the data and make it suitable for training.\n",
    "\n",
    "All TorchVision datasets have two parameters -`transform` to modify the\n",
    "features and `target_transform` to modify the labels - that accept\n",
    "callables containing the transformation logic. The\n",
    "[torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
    "module offers several commonly-used transforms out of the box.\n",
    "\n",
    "The FashionMNIST features are in PIL Image format, and the labels are\n",
    "integers. For training, we need the features as normalized tensors, and\n",
    "the labels as one-hot encoded tensors. To make these transformations, we\n",
    "use `ToTensor` and `Lambda`.\n",
    "\n",
    "### ToTensor()\n",
    "\n",
    "[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)\n",
    "converts a PIL image or NumPy `ndarray` into a `FloatTensor`. and scales\n",
    "the image\\'s pixel intensity values in the range \\[0., 1.\\]\n",
    "\n",
    "### Lambda Transforms\n",
    "\n",
    "Lambda transforms apply any user-defined lambda function. Here, we\n",
    "define a function to turn the integer into a one-hot encoded tensor. It\n",
    "first creates a zero tensor of size 10 (the number of labels in our\n",
    "dataset) and calls\n",
    "[scatter\\_](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html)\n",
    "which assigns a `value=1` on the index as given by the label `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "### Build the Neural Network\n",
    "\n",
    "Neural networks comprise of layers/modules that perform operations on\n",
    "data. The [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace\n",
    "provides all the building blocks you need to build your own neural\n",
    "network. Every module in PyTorch subclasses the\n",
    "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "A neural network is a module itself that consists of other modules\n",
    "(layers). This nested structure allows for building and managing complex\n",
    "architectures easily.\n",
    "\n",
    "In the following sections, we\\'ll build a neural network to classify\n",
    "images in the FashionMNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Class\n",
    "\n",
    "We define our neural network by subclassing `nn.Module`, and initialize\n",
    "the neural network layers in `__init__`. Every `nn.Module` subclass\n",
    "implements the operations on input data in the `forward` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model, we pass it the input data. This executes the model\\'s\n",
    "`forward`, along with some [background\n",
    "operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).\n",
    "Do not call `model.forward()` directly!\n",
    "\n",
    "Calling the model on the input returns a 2-dimensional tensor with dim=0\n",
    "corresponding to each output of 10 raw predicted values for each class,\n",
    "and dim=1 corresponding to the individual values of each output. We get\n",
    "the prediction probabilities by passing it through an instance of the\n",
    "`nn.Softmax` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Layers\n",
    "\n",
    "Let\\'s break down the layers in the FashionMNIST model. To illustrate\n",
    "it, we will take a sample minibatch of 3 images of size 28x28 and see\n",
    "what happens to it as we pass it through the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Flatten\n",
    "\n",
    "We initialize the\n",
    "[nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n",
    "layer to convert each 2D 28x28 image into a contiguous array of 784\n",
    "pixel values ( the minibatch dimension (at dim=0) is maintained).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear\n",
    "\n",
    "The [linear\n",
    "layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "is a module that applies a linear transformation on the input using its\n",
    "stored weights and biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ReLU\n",
    "\n",
    "Non-linear activations are what create the complex mappings between the\n",
    "model\\'s inputs and outputs. They are applied after linear\n",
    "transformations to introduce *nonlinearity*, helping neural networks\n",
    "learn a wide variety of phenomena.\n",
    "\n",
    "In this model, we use\n",
    "[nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
    "between our linear layers, but there\\'s other activations to introduce\n",
    "non-linearity in your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-3.1540e-02, -1.5555e-01, -4.0794e-01, -1.6999e-01, -6.4646e-02,\n",
      "         -1.9358e-01, -2.2942e-01, -3.8007e-02, -3.2575e-01, -3.3794e-01,\n",
      "         -2.9540e-01, -1.9502e-01, -1.8220e-01,  4.0613e-02,  2.2113e-02,\n",
      "          5.2996e-02, -3.3352e-02,  3.4086e-01, -3.0559e-02, -2.6503e-01],\n",
      "        [-3.4629e-01,  6.6547e-02, -7.7879e-01, -2.7901e-01, -4.9018e-02,\n",
      "         -4.3725e-01,  1.1751e-01, -3.2069e-01, -4.1478e-01,  7.1298e-02,\n",
      "          3.0193e-01, -6.1575e-02, -2.5639e-01,  6.4421e-02, -2.6663e-01,\n",
      "         -1.1187e-04, -2.1553e-01,  2.7886e-01,  1.7046e-01, -3.3301e-01],\n",
      "        [-3.1233e-01,  4.5994e-01, -4.7507e-01, -2.7212e-02, -6.2979e-02,\n",
      "         -2.8331e-01, -2.6563e-01, -2.7401e-01, -9.3969e-02,  2.5433e-01,\n",
      "         -1.8697e-01,  1.0256e-02, -3.3530e-01,  8.3531e-03,  2.2403e-01,\n",
      "         -1.7757e-01,  1.4530e-01,  4.5996e-01,  6.1837e-02, -4.3811e-01]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0406, 0.0221, 0.0530, 0.0000, 0.3409,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0665, 0.0000, 0.0000, 0.0000, 0.0000, 0.1175, 0.0000, 0.0000,\n",
      "         0.0713, 0.3019, 0.0000, 0.0000, 0.0644, 0.0000, 0.0000, 0.0000, 0.2789,\n",
      "         0.1705, 0.0000],\n",
      "        [0.0000, 0.4599, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2543, 0.0000, 0.0103, 0.0000, 0.0084, 0.2240, 0.0000, 0.1453, 0.4600,\n",
      "         0.0618, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential\n",
    "\n",
    "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
    "is an ordered container of modules. The data is passed through all the\n",
    "modules in the same order as defined. You can use sequential containers\n",
    "to put together a quick network like `seq_modules`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Softmax\n",
    "\n",
    "The last linear layer of the neural network returns [logits]{.title-ref}\n",
    "- raw values in \\[-infty, infty\\] - which are passed to the\n",
    "[nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)\n",
    "module. The logits are scaled to values \\[0, 1\\] representing the\n",
    "model\\'s predicted probabilities for each class. `dim` parameter\n",
    "indicates the dimension along which the values must sum to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "\n",
    "Many layers inside a neural network are *parameterized*, i.e. have\n",
    "associated weights and biases that are optimized during training.\n",
    "Subclassing `nn.Module` automatically tracks all fields defined inside\n",
    "your model object, and makes all parameters accessible using your\n",
    "model\\'s `parameters()` or `named_parameters()` methods.\n",
    "\n",
    "In this example, we iterate over each parameter, and print its size and\n",
    "a preview of its values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0348, -0.0308, -0.0048,  ...,  0.0120,  0.0327,  0.0125],\n",
      "        [ 0.0046,  0.0287,  0.0287,  ...,  0.0183, -0.0086,  0.0185]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0026, -0.0231], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0196, -0.0005, -0.0050,  ...,  0.0310, -0.0013, -0.0398],\n",
      "        [-0.0090,  0.0228, -0.0256,  ..., -0.0274,  0.0072, -0.0119]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0207,  0.0053], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0372, -0.0298,  0.0270,  ..., -0.0034, -0.0417,  0.0033],\n",
      "        [-0.0422, -0.0344, -0.0141,  ...,  0.0089, -0.0129, -0.0345]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0293,  0.0076], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation with `torch.autograd`\n",
    "\n",
    "When training neural networks, the most frequently used algorithm is\n",
    "**back propagation**. In this algorithm, parameters (model weights) are\n",
    "adjusted according to the **gradient** of the loss function with respect\n",
    "to the given parameter.\n",
    "\n",
    "To compute those gradients, PyTorch has a built-in differentiation\n",
    "engine called `torch.autograd`. It supports automatic computation of\n",
    "gradient for any computational graph.\n",
    "\n",
    "Consider the simplest one-layer neural network, with input `x`,\n",
    "parameters `w` and `b`, and some loss function. It can be defined in\n",
    "PyTorch in the following manner:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors, Functions and Computational graph\n",
    "\n",
    "This code defines the following **computational graph**:\n",
    "\n",
    "![](https://pytorch.org/tutorials/_static/img/basics/comp-graph.png)\n",
    "\n",
    "In this network, `w` and `b` are **parameters**, which we need to\n",
    "optimize. Thus, we need to be able to compute the gradients of loss\n",
    "function with respect to those variables. In order to do that, we set\n",
    "the `requires_grad` property of those tensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that we apply to tensors to construct computational graph is\n",
    "in fact an object of class `Function`. This object knows how to compute\n",
    "the function in the *forward* direction, and also how to compute its\n",
    "derivative during the *backward propagation* step. A reference to the\n",
    "backward propagation function is stored in `grad_fn` property of a\n",
    "tensor. You can find more information of `Function` [in the\n",
    "documentation](https://pytorch.org/docs/stable/autograd.html#function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7a3bec6c97e0>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7a3bec6c9600>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients\n",
    "\n",
    "To optimize weights of parameters in the neural network, we need to\n",
    "compute the derivatives of our loss function with respect to parameters,\n",
    "namely, we need $\\frac{\\partial loss}{\\partial w}$ and\n",
    "$\\frac{\\partial loss}{\\partial b}$ under some fixed values of `x` and\n",
    "`y`. To compute those derivatives, we call `loss.backward()`, and then\n",
    "retrieve the values from `w.grad` and `b.grad`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3007, 0.3030, 0.2859],\n",
      "        [0.3007, 0.3030, 0.2859],\n",
      "        [0.3007, 0.3030, 0.2859],\n",
      "        [0.3007, 0.3030, 0.2859],\n",
      "        [0.3007, 0.3030, 0.2859]])\n",
      "tensor([0.3007, 0.3030, 0.2859])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
    "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
    "<ul>\n",
    "<li>We can only obtain the <code>grad</code> properties for the leafnodes of the computational graph, which have <code>requires_grad</code> propertyset to <code>True</code>. For all other nodes in our graph, gradients will not beavailable.- We can only perform gradient calculations using<code>backward</code> once on a given graph, for performance reasons. If we needto do several <code>backward</code> calls on the same graph, we need to pass<code>retain_graph=True</code> to the <code>backward</code> call.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "### Disabling Gradient Tracking\n",
    "\n",
    "By default, all tensors with `requires_grad=True` are tracking their\n",
    "computational history and support gradient computation. However, there\n",
    "are some cases when we do not need to do that, for example, when we have\n",
    "trained the model and just want to apply it to some input data, i.e. we\n",
    "only want to do *forward* computations through the network. We can stop\n",
    "tracking computations by surrounding our computation code with\n",
    "`torch.no_grad()` block:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieve the same result is to use the `detach()` method\n",
    "on the tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are reasons you might want to disable gradient tracking:\n",
    "\n",
    ":   -   To mark some parameters in your neural network as **frozen\n",
    "        parameters**.\n",
    "    -   To **speed up computations** when you are only doing forward\n",
    "        pass, because computations on tensors that do not track\n",
    "        gradients would be more efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on Computational Graphs\n",
    "\n",
    "Conceptually, autograd keeps a record of data (tensors) and all executed\n",
    "operations (along with the resulting new tensors) in a directed acyclic\n",
    "graph (DAG) consisting of\n",
    "[Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
    "objects. In this DAG, leaves are the input tensors, roots are the output\n",
    "tensors. By tracing this graph from roots to leaves, you can\n",
    "automatically compute the gradients using the chain rule.\n",
    "\n",
    "In a forward pass, autograd does two things simultaneously:\n",
    "\n",
    "-   run the requested operation to compute a resulting tensor\n",
    "-   maintain the operation's *gradient function* in the DAG.\n",
    "\n",
    "The backward pass kicks off when `.backward()` is called on the DAG\n",
    "root. `autograd` then:\n",
    "\n",
    "-   computes the gradients from each `.grad_fn`,\n",
    "-   accumulates them in the respective tensor's `.grad` attribute\n",
    "-   using the chain rule, propagates all the way to the leaf tensors.\n",
    "\n",
    "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
    "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
    "<p>An important thing to note is that the graph is recreated from scratch; after each<code>.backward()</code> call, autograd starts populating a new graph. This isexactly what allows you to use control flow statements in your model;you can change the shape, size and operations at every iteration ifneeded.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Reading: Tensor Gradients and Jacobian Products\n",
    "\n",
    "In many cases, we have a scalar loss function, and we need to compute\n",
    "the gradient with respect to some parameters. However, there are cases\n",
    "when the output function is an arbitrary tensor. In this case, PyTorch\n",
    "allows you to compute so-called **Jacobian product**, and not the actual\n",
    "gradient.\n",
    "\n",
    "For a vector function $\\vec{y}=f(\\vec{x})$, where\n",
    "$\\vec{x}=\\langle x_1,\\dots,x_n\\rangle$ and\n",
    "$\\vec{y}=\\langle y_1,\\dots,y_m\\rangle$, a gradient of $\\vec{y}$ with\n",
    "respect to $\\vec{x}$ is given by **Jacobian matrix**:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "J=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\n",
    "\\end{aligned}$$\n",
    "\n",
    "Instead of computing the Jacobian matrix itself, PyTorch allows you to\n",
    "compute **Jacobian Product** $v^T\\cdot J$ for a given input vector\n",
    "$v=(v_1 \\dots v_m)$. This is achieved by calling `backward` with $v$ as\n",
    "an argument. The size of $v$ should be the same as the size of the\n",
    "original tensor, with respect to which we want to compute the product:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n",
      "\n",
      "Second call\n",
      "tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "out = (inp+1).pow(2).t()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"First call\\n{inp.grad}\")\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nSecond call\\n{inp.grad}\")\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we call `backward` for the second time with the same\n",
    "argument, the value of the gradient is different. This happens because\n",
    "when doing `backward` propagation, PyTorch **accumulates the\n",
    "gradients**, i.e. the value of computed gradients is added to the `grad`\n",
    "property of all leaf nodes of computational graph. If you want to\n",
    "compute the proper gradients, you need to zero out the `grad` property\n",
    "before. In real-life training an *optimizer* helps us to do this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
    "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
    "<p>Previously we were calling <code>backward()</code> function withoutparameters. This is essentially equivalent to calling<code>backward(torch.tensor(1.0))</code>, which is a useful way to compute thegradients in case of a scalar-valued function, such as loss duringneural network training.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Loop\n",
    "\n",
    "### Optimizing Model Parameters\n",
    "\n",
    "Now that we have a model and data it\\'s time to train, validate and test\n",
    "our model by optimizing its parameters on our data. Training a model is\n",
    "an iterative process; in each iteration the model makes a guess about\n",
    "the output, calculates the error in its guess (*loss*), collects the\n",
    "derivatives of the error with respect to its parameters (as we saw in\n",
    "the [previous section](autograd_tutorial.html)), and **optimizes** these\n",
    "parameters using gradient descent. For a more detailed walkthrough of\n",
    "this process, check out this video on [backpropagation from\n",
    "3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8).\n",
    "\n",
    "Prerequisite Code\n",
    "-----------------\n",
    "\n",
    "We load the code from the previous sections on [Datasets &\n",
    "DataLoaders](data_tutorial.html) and [Build\n",
    "Model](buildmodel_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Hyperparameters are adjustable parameters that let you control the model\n",
    "optimization process. Different hyperparameter values can impact model\n",
    "training and convergence rates ([read\n",
    "more](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)\n",
    "about hyperparameter tuning)\n",
    "\n",
    "We define the following hyperparameters for training:\n",
    "\n",
    ":   -   **Number of Epochs** - the number times to iterate over the\n",
    "        dataset\n",
    "    -   **Batch Size** - the number of data samples propagated through\n",
    "        the network before the parameters are updated\n",
    "    -   **Learning Rate** - how much to update models parameters at each\n",
    "        batch/epoch. Smaller values yield slow learning speed, while\n",
    "        large values may result in unpredictable behavior during\n",
    "        training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Loop\n",
    "\n",
    "Once we set our hyperparameters, we can then train and optimize our\n",
    "model with an optimization loop. Each iteration of the optimization loop\n",
    "is called an **epoch**.\n",
    "\n",
    "Each epoch consists of two main parts:\n",
    "\n",
    ":   -   **The Train Loop** - iterate over the training dataset and try\n",
    "        to converge to optimal parameters.\n",
    "    -   **The Validation/Test Loop** - iterate over the test dataset to\n",
    "        check if model performance is improving.\n",
    "\n",
    "Let\\'s briefly familiarize ourselves with some of the concepts used in\n",
    "the training loop. Jump ahead to see the\n",
    "`full-impl-label`{.interpreted-text role=\"ref\"} of the optimization\n",
    "loop.\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "When presented with some training data, our untrained network is likely\n",
    "not to give the correct answer. **Loss function** measures the degree of\n",
    "dissimilarity of obtained result to the target value, and it is the loss\n",
    "function that we want to minimize during training. To calculate the loss\n",
    "we make a prediction using the inputs of our given data sample and\n",
    "compare it against the true data label value.\n",
    "\n",
    "Common loss functions include\n",
    "[nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)\n",
    "(Mean Square Error) for regression tasks, and\n",
    "[nn.NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss)\n",
    "(Negative Log Likelihood) for classification.\n",
    "[nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)\n",
    "combines `nn.LogSoftmax` and `nn.NLLLoss`.\n",
    "\n",
    "We pass our model\\'s output logits to `nn.CrossEntropyLoss`, which will\n",
    "normalize the logits and compute the prediction error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Optimization is the process of adjusting model parameters to reduce\n",
    "model error in each training step. **Optimization algorithms** define\n",
    "how this process is performed (in this example we use Stochastic\n",
    "Gradient Descent). All optimization logic is encapsulated in the\n",
    "`optimizer` object. Here, we use the SGD optimizer; additionally, there\n",
    "are many [different\n",
    "optimizers](https://pytorch.org/docs/stable/optim.html) available in\n",
    "PyTorch such as ADAM and RMSProp, that work better for different kinds\n",
    "of models and data.\n",
    "\n",
    "We initialize the optimizer by registering the model\\'s parameters that\n",
    "need to be trained, and passing in the learning rate hyperparameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the training loop, optimization happens in three steps:\n",
    "\n",
    ":   -   Call `optimizer.zero_grad()` to reset the gradients of model\n",
    "        parameters. Gradients by default add up; to prevent\n",
    "        double-counting, we explicitly zero them at each iteration.\n",
    "    -   Backpropagate the prediction loss with a call to\n",
    "        `loss.backward()`. PyTorch deposits the gradients of the loss\n",
    "        w.r.t. each parameter.\n",
    "    -   Once we have our gradients, we call `optimizer.step()` to adjust\n",
    "        the parameters by the gradients collected in the backward pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.295837  [   64/60000]\n",
      "loss: 2.293579  [ 6464/60000]\n",
      "loss: 2.272922  [12864/60000]\n",
      "loss: 2.270849  [19264/60000]\n",
      "loss: 2.263756  [25664/60000]\n",
      "loss: 2.222189  [32064/60000]\n",
      "loss: 2.237807  [38464/60000]\n",
      "loss: 2.196224  [44864/60000]\n",
      "loss: 2.189372  [51264/60000]\n",
      "loss: 2.169547  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 37.8%, Avg loss: 2.157363 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.157923  [   64/60000]\n",
      "loss: 2.159187  [ 6464/60000]\n",
      "loss: 2.095220  [12864/60000]\n",
      "loss: 2.115452  [19264/60000]\n",
      "loss: 2.085444  [25664/60000]\n",
      "loss: 2.005141  [32064/60000]\n",
      "loss: 2.042828  [38464/60000]\n",
      "loss: 1.950053  [44864/60000]\n",
      "loss: 1.950055  [51264/60000]\n",
      "loss: 1.900573  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.886302 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.903745  [   64/60000]\n",
      "loss: 1.892251  [ 6464/60000]\n",
      "loss: 1.762474  [12864/60000]\n",
      "loss: 1.813374  [19264/60000]\n",
      "loss: 1.737207  [25664/60000]\n",
      "loss: 1.656015  [32064/60000]\n",
      "loss: 1.694675  [38464/60000]\n",
      "loss: 1.577439  [44864/60000]\n",
      "loss: 1.606302  [51264/60000]\n",
      "loss: 1.516862  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 1.522544 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.575289  [   64/60000]\n",
      "loss: 1.557392  [ 6464/60000]\n",
      "loss: 1.393409  [12864/60000]\n",
      "loss: 1.478146  [19264/60000]\n",
      "loss: 1.389225  [25664/60000]\n",
      "loss: 1.351302  [32064/60000]\n",
      "loss: 1.382229  [38464/60000]\n",
      "loss: 1.290686  [44864/60000]\n",
      "loss: 1.336439  [51264/60000]\n",
      "loss: 1.240304  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.259260 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.324633  [   64/60000]\n",
      "loss: 1.321722  [ 6464/60000]\n",
      "loss: 1.143631  [12864/60000]\n",
      "loss: 1.256708  [19264/60000]\n",
      "loss: 1.156322  [25664/60000]\n",
      "loss: 1.153968  [32064/60000]\n",
      "loss: 1.185743  [38464/60000]\n",
      "loss: 1.111929  [44864/60000]\n",
      "loss: 1.160879  [51264/60000]\n",
      "loss: 1.076737  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.092271 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.151437  [   64/60000]\n",
      "loss: 1.170216  [ 6464/60000]\n",
      "loss: 0.976610  [12864/60000]\n",
      "loss: 1.115719  [19264/60000]\n",
      "loss: 1.010082  [25664/60000]\n",
      "loss: 1.019818  [32064/60000]\n",
      "loss: 1.063249  [38464/60000]\n",
      "loss: 0.997670  [44864/60000]\n",
      "loss: 1.045142  [51264/60000]\n",
      "loss: 0.974185  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.984158 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.030561  [   64/60000]\n",
      "loss: 1.072613  [ 6464/60000]\n",
      "loss: 0.862243  [12864/60000]\n",
      "loss: 1.021772  [19264/60000]\n",
      "loss: 0.918092  [25664/60000]\n",
      "loss: 0.925213  [32064/60000]\n",
      "loss: 0.983691  [38464/60000]\n",
      "loss: 0.923599  [44864/60000]\n",
      "loss: 0.965144  [51264/60000]\n",
      "loss: 0.906066  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.910887 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.942412  [   64/60000]\n",
      "loss: 1.005313  [ 6464/60000]\n",
      "loss: 0.780685  [12864/60000]\n",
      "loss: 0.956048  [19264/60000]\n",
      "loss: 0.857182  [25664/60000]\n",
      "loss: 0.855978  [32064/60000]\n",
      "loss: 0.928625  [38464/60000]\n",
      "loss: 0.874305  [44864/60000]\n",
      "loss: 0.908068  [51264/60000]\n",
      "loss: 0.857662  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.858548 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.875719  [   64/60000]\n",
      "loss: 0.955345  [ 6464/60000]\n",
      "loss: 0.720101  [12864/60000]\n",
      "loss: 0.907416  [19264/60000]\n",
      "loss: 0.814186  [25664/60000]\n",
      "loss: 0.803904  [32064/60000]\n",
      "loss: 0.887385  [38464/60000]\n",
      "loss: 0.840226  [44864/60000]\n",
      "loss: 0.865861  [51264/60000]\n",
      "loss: 0.820980  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.819209 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.823296  [   64/60000]\n",
      "loss: 0.915483  [ 6464/60000]\n",
      "loss: 0.673277  [12864/60000]\n",
      "loss: 0.870154  [19264/60000]\n",
      "loss: 0.781714  [25664/60000]\n",
      "loss: 0.763809  [32064/60000]\n",
      "loss: 0.854279  [38464/60000]\n",
      "loss: 0.815579  [44864/60000]\n",
      "loss: 0.833453  [51264/60000]\n",
      "loss: 0.791488  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.788145 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save, Load and Use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Model Weights\n",
    "\n",
    "PyTorch models store the learned parameters in an internal state\n",
    "dictionary, called `state_dict`. These can be persisted via the\n",
    "`torch.save` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/sunzid/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:15<00:00, 35.8MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load model weights, you need to create an instance of the same model\n",
    "first, and then load the parameters using `load_state_dict()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
    "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
    "<p>be sure to call <code>model.eval()</code> method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models with Shapes\n",
    "\n",
    "When loading model weights, we needed to instantiate the model class\n",
    "first, because the class defines the structure of a network. We might\n",
    "want to save the structure of this class together with the model, in\n",
    "which case we can pass `model` (and not `model.state_dict()`) to the\n",
    "saving function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
    "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
    "<p>This approach uses Python <a href=\"https://docs.python.org/3/library/pickle.html\">pickle</a> module when serializing the model, thus it relies on the actual class definition to be available when loading the model.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Tutorial on CartPole\n",
    "\n",
    "**Task**\n",
    "\n",
    "The agent has to decide between two actions - moving the cart left or\n",
    "right - so that the pole attached to it stays upright. You can find more\n",
    "information about the environment and other more challenging\n",
    "environments at [Gymnasium\\'s\n",
    "website](https://gymnasium.farama.org/environments/classic_control/cart_pole/).\n",
    "\n",
    "![CartPole](https://pytorch.org/tutorials/_static/img/cartpole.gif)\n",
    "\n",
    "As the agent observes the current state of the environment and chooses\n",
    "an action, the environment *transitions* to a new state, and also\n",
    "returns a reward that indicates the consequences of the action. In this\n",
    "task, rewards are +1 for every incremental timestep and the environment\n",
    "terminates if the pole falls over too far or the cart moves more than\n",
    "2.4 units away from center. This means better performing scenarios will\n",
    "run for longer duration, accumulating larger return.\n",
    "\n",
    "The CartPole task is designed so that the inputs to the agent are 4 real\n",
    "values representing the environment state (position, velocity, etc.). We\n",
    "take these 4 inputs without any scaling and pass them through a small\n",
    "fully-connected network with 2 outputs, one for each action. The network\n",
    "is trained to predict the expected value for each action, given the\n",
    "input state. The action with the highest expected value is then chosen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Memory\n",
    "\n",
    "We\\'ll be using experience replay memory for training our DQN. It stores\n",
    "the transitions that the agent observes, allowing us to reuse this data\n",
    "later. By sampling from it randomly, the transitions that build up a\n",
    "batch are decorrelated. It has been shown that this greatly stabilizes\n",
    "and improves the DQN training procedure.\n",
    "\n",
    "For this, we\\'re going to need two classes:\n",
    "\n",
    "-   `Transition` - a named tuple representing a single transition in our\n",
    "    environment. It essentially maps (state, action) pairs to their\n",
    "    (next\\_state, reward) result, with the state being the screen\n",
    "    difference image as described later on.\n",
    "-   `ReplayMemory` - a cyclic buffer of bounded size that holds the\n",
    "    transitions observed recently. It also implements a `.sample()`\n",
    "    method for selecting a random batch of transitions for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let\\'s define our model. But first, let\\'s quickly recap what a DQN\n",
    "is.\n",
    "\n",
    "### DQN algorithm\n",
    "\n",
    "Our environment is deterministic, so all equations presented here are\n",
    "also formulated deterministically for the sake of simplicity. In the\n",
    "reinforcement learning literature, they would also contain expectations\n",
    "over stochastic transitions in the environment.\n",
    "\n",
    "Our aim will be to train a policy that tries to maximize the discounted,\n",
    "cumulative reward\n",
    "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where $R_{t_0}$\n",
    "is also known as the *return*. The discount, $\\gamma$, should be a\n",
    "constant between $0$ and $1$ that ensures the sum converges. A lower\n",
    "$\\gamma$ makes rewards from the uncertain far future less important for\n",
    "our agent than the ones in the near future that it can be fairly\n",
    "confident about. It also encourages agents to collect reward closer in\n",
    "time than equivalent rewards that are temporally far away in the future.\n",
    "\n",
    "The main idea behind Q-learning is that if we had a function\n",
    "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell us\n",
    "what our return would be, if we were to take an action in a given state,\n",
    "then we could easily construct a policy that maximizes our rewards:\n",
    "\n",
    "$$\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)$$\n",
    "\n",
    "However, we don\\'t know everything about the world, so we don\\'t have\n",
    "access to $Q^*$. But, since neural networks are universal function\n",
    "approximators, we can simply create one and train it to resemble $Q^*$.\n",
    "\n",
    "For our training update rule, we\\'ll use a fact that every $Q$ function\n",
    "for some policy obeys the Bellman equation:\n",
    "\n",
    "$$Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))$$\n",
    "\n",
    "The difference between the two sides of the equality is known as the\n",
    "temporal difference error, $\\delta$:\n",
    "\n",
    "$$\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))$$\n",
    "\n",
    "To minimize this error, we will use the [Huber\n",
    "loss](https://en.wikipedia.org/wiki/Huber_loss). The Huber loss acts\n",
    "like the mean squared error when the error is small, but like the mean\n",
    "absolute error when the error is large - this makes it more robust to\n",
    "outliers when the estimates of $Q$ are very noisy. We calculate this\n",
    "over a batch of transitions, $B$, sampled from the replay memory:\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
    "  \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
    "  |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Q-network\n",
    "---------\n",
    "\n",
    "Our model will be a feed forward neural network that takes in the\n",
    "difference between the current and previous screen patches. It has two\n",
    "outputs, representing $Q(s, \\mathrm{left})$ and $Q(s, \\mathrm{right})$\n",
    "(where $s$ is the input to the network). In effect, the network is\n",
    "trying to predict the *expected return* of taking each action given the\n",
    "current input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Hyperparameters and utilities\n",
    "-----------------------------\n",
    "\n",
    "This cell instantiates our model and its optimizer, and defines some\n",
    "utilities:\n",
    "\n",
    "-   `select_action` - will select an action according to an epsilon\n",
    "    greedy policy. Simply put, we\\'ll sometimes use our model for\n",
    "    choosing the action, and sometimes we\\'ll just sample one uniformly.\n",
    "    The probability of choosing a random action will start at\n",
    "    `EPS_START` and will decay exponentially towards `EPS_END`.\n",
    "    `EPS_DECAY` controls the rate of the decay.\n",
    "-   `plot_durations` - a helper for plotting the duration of episodes,\n",
    "    along with an average over the last 100 episodes (the measure used\n",
    "    in the official evaluations). The plot will be underneath the cell\n",
    "    containing the main training loop, and will update after every\n",
    "    episode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Finally, the code for training our model.\n",
    "\n",
    "Here, you can find an `optimize_model` function that performs a single\n",
    "step of the optimization. It first samples a batch, concatenates all the\n",
    "tensors into a single one, computes $Q(s_t, a_t)$ and\n",
    "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our loss. By\n",
    "definition we set $V(s) = 0$ if $s$ is a terminal state. We also use a\n",
    "target network to compute $V(s_{t+1})$ for added stability. The target\n",
    "network is updated at every step with a [soft\n",
    "update](https://arxiv.org/pdf/1509.02971.pdf) controlled by the\n",
    "hyperparameter `TAU`, which was previously defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Batch:\n",
      "tensor([[0.7745, 0.6473],\n",
      "        [0.8660, 0.0287],\n",
      "        [0.1187, 0.7957],\n",
      "        [0.7061, 0.4107]], device='cuda:0')\n",
      "Action Batch:\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Reward Batch:\n",
      "tensor([0.8921, 0.3901, 0.2667, 0.5895], device='cuda:0')\n",
      "State-Action Values:\n",
      "tensor([[-0.5784],\n",
      "        [ 1.1745],\n",
      "        [ 0.2828],\n",
      "        [ 0.8721]], device='cuda:0', grad_fn=<GatherBackward0>)\n",
      "Next State Values:\n",
      "tensor([0.4592, 0.9632, 0.6243, 0.0000], device='cuda:0')\n",
      "Expected State-Action Values:\n",
      "tensor([1.3467, 1.3437, 0.8848, 0.5895], device='cuda:0')\n",
      "Loss:\n",
      "0.41513964533805847\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "# Define the transition tuple\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "# Dummy replay memory\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "# Define a simple neural network for policy and target nets\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "GAMMA = 0.99\n",
    "input_size = 2\n",
    "output_size = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize networks\n",
    "policy_net = SimpleNet(input_size, output_size).to(device)\n",
    "target_net = SimpleNet(input_size, output_size).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize replay memory\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "# Populate replay memory with dummy data\n",
    "for _ in range(10):\n",
    "    state = torch.rand((1, input_size), device=device)\n",
    "    action = torch.tensor([[random.randrange(output_size)]], device=device)\n",
    "    next_state = torch.rand((1, input_size), device=device) if random.random() > 0.5 else None\n",
    "    reward = torch.tensor([random.random()], device=device)\n",
    "    memory.push(state, action, next_state, reward)\n",
    "\n",
    "# Define the optimize_model function\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print outputs for demonstration\n",
    "    print(\"State Batch:\")\n",
    "    print(state_batch)\n",
    "    print(\"Action Batch:\")\n",
    "    print(action_batch)\n",
    "    print(\"Reward Batch:\")\n",
    "    print(reward_batch)\n",
    "    print(\"State-Action Values:\")\n",
    "    print(state_action_values)\n",
    "    print(\"Next State Values:\")\n",
    "    print(next_state_values)\n",
    "    print(\"Expected State-Action Values:\")\n",
    "    print(expected_state_action_values)\n",
    "    print(\"Loss:\")\n",
    "    print(loss.item())\n",
    "\n",
    "# Run a single optimization loop\n",
    "optimize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the main training loop. At the beginning we reset\n",
    "the environment and obtain the initial `state` Tensor. Then, we sample\n",
    "an action, execute it, observe the next state and the reward (always 1),\n",
    "and optimize our model once. When the episode ends (our model fails), we\n",
    "restart the loop.\n",
    "\n",
    "Below, [num\\_episodes]{.title-ref} is set to 600 if a GPU is available,\n",
    "otherwise 50 episodes are scheduled so training does not take too long.\n",
    "However, 50 episodes is insufficient for to observe good performance on\n",
    "CartPole. You should see the model constantly achieve 500 steps within\n",
    "600 training episodes. Training RL agents can be a noisy process, so\n",
    "restarting training can produce better results if convergence is not\n",
    "observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACUaElEQVR4nO3dd3wUdf748de2bHpIKAmhI72qoBQLIE0s2M7eUM+zn1jOO/TuxAZ+uZ/oiXd4VrBixd7AAiIWiiBNUHoLNaRns2V+f2x2d2Z2tmaTTcL76SOP7M7OzH52Epl33p/35/MxKYqiIIQQQgjRTJmT3QAhhBBCiPokwY4QQgghmjUJdoQQQgjRrEmwI4QQQohmTYIdIYQQQjRrEuwIIYQQolmTYEcIIYQQzZoEO0IIIYRo1iTYEUIIIUSzJsGOECLp5syZg8lk8n9ZrVbatm3LJZdcwm+//Zbs5mEymZg6dar/+fr165k6dSrbtm1LWpuEENGTYEcI0Wi8+OKLfP/99yxcuJBbb72VDz74gJNPPpni4uJkN01j/fr1PPDAAxLsCNFEWJPdACGE8OnXrx+DBw8GYOTIkbjdbu6//37ee+89rrnmmiS3TgjRVElmRwjRaPkCn3379vm3LV++nIkTJ5KXl0dqairHHXccb775pua4yspK7r77brp06UJqaip5eXkMHjyY119/3b/PyJEjGTlyZNB7Tpo0ic6dO4ds05w5c7jwwgsBGDVqlL/rbc6cOfF/UCFEvZLMjhCi0dq6dSsAPXr0AODrr7/m9NNPZ8iQITz99NPk5OQwb948Lr74YiorK5k0aRIAd955Jy+//DIPP/wwxx13HBUVFaxdu5ZDhw7VuU1nnnkm06ZN49577+U///kPxx9/PADHHHNMnc8thKgfEuwIIRoNt9uNy+Wiurqa7777jocffphTTz2ViRMnAnDzzTfTt29fvvrqK6xW7z9f48eP5+DBg9x7771cddVVmM1mvvvuO8aNG8cdd9zhP/eZZ56ZkDa2bt2a7t27A9CnTx+GDh2akPMKIeqPdGMJIRqNoUOHYrPZyMrK4vTTTyc3N5f3338fq9XK77//zq+//srll18OgMvl8n+dccYZ7N27l40bNwJw4okn8umnn/K3v/2Nb775hqqqqmR+LCFEkkmwI4RoNF566SWWLVvGV199xQ033MCGDRu49NJLgUDdzt13343NZtN83XzzzQAcPHgQgCeffJK//vWvvPfee4waNYq8vDzOPffcRjGMXQjR8KQbSwjRaPTu3dtflDxq1CjcbjfPPfccb7/9Nv379wdgypQpnH/++YbH9+zZE4CMjAweeOABHnjgAfbt2+fP8px99tn8+uuvAKSmplJSUhJ0Dl/AJIRoPiTYEUI0WjNmzOCdd97hn//8J2vXrqV79+6sXr2aadOmRX2O/Px8Jk2axOrVq3niiSeorKwkPT2dzp0789Zbb+FwOLDb7QAcOnSIpUuXkp2dHfacvv2le0yIpkGCHSFEo5Wbm8uUKVO45557eO211/jf//7HhAkTGD9+PJMmTaJdu3YcPnyYDRs2sHLlSt566y0AhgwZwllnncWAAQPIzc1lw4YNvPzyywwbNoz09HQArrzySv73v/9xxRVXcP3113Po0CFmzJgRMdAB73xAAM888wxZWVmkpqbSpUsXWrZsWX8XQwgRN6nZEUI0arfddhsdO3bkwQcf5NRTT+Wnn36iRYsWTJ48mTFjxnDTTTexcOFCxowZ4z/mtNNO44MPPuCaa65h3LhxzJgxg6uuuooPP/zQv89JJ53E3LlzWbduHeeccw4PP/wwU6ZMMZx7R69Lly488cQTrF69mpEjR3LCCSdozi2EaFxMiqIoyW6EEEIIIUR9kcyOEEIIIZo1CXaEEEII0axJsCOEEEKIZk2CHSGEEEI0axLsCCGEEKJZk2BHCCGEEM2aTCoIeDwe9uzZQ1ZWFiaTKdnNEUIIIUQUFEWhrKyMwsJCzObQ+RsJdoA9e/bQoUOHZDdDCCGEEHHYuXMn7du3D/m6BDtAVlYW4L1Y0UwVL4QQQojkKy0tpUOHDv77eCgS7IC/6yo7O1uCHSGEEKKJiVSCIgXKQgghhGjWJNgRQgghRLMmwY4QQgghmjUJdoQQQgjRrEmwI4QQQohmTYIdIYQQQjRrEuwIIYQQolmTYEcIIYQQzZoEO0IIIYRo1iTYEUIIIUSzltRgZ+rUqZhMJs1XQUGB/3VFUZg6dSqFhYWkpaUxcuRI1q1bpzmHw+Hgtttuo1WrVmRkZDBx4kR27drV0B9FCCGEEI1U0jM7ffv2Ze/evf6vNWvW+F+bMWMGM2fO5KmnnmLZsmUUFBQwduxYysrK/PtMnjyZ+fPnM2/ePJYsWUJ5eTlnnXUWbrc7GR9HCCGEEI1M0hcCtVqtmmyOj6IoPPHEE9x3332cf/75AMydO5f8/Hxee+01brjhBkpKSnj++ed5+eWXGTNmDACvvPIKHTp0YOHChYwfP75BP4sQQghhxONRqHF7SLVZqKpxk5ZiAWB/WTVZdhs1bg9l1c4kt7J+tUhPIdOenLAj6cHOb7/9RmFhIXa7nSFDhjBt2jS6du3K1q1bKSoqYty4cf597XY7I0aMYOnSpdxwww2sWLECp9Op2aewsJB+/fqxdOnSkMGOw+HA4XD4n5eWltbfBxRCCHHUmzRnGcu3HeaSEzrywndbeeW6IWzYW8ojn2xIdtMazLTz+nPZkI5Jee+kBjtDhgzhpZdeokePHuzbt4+HH36Y4cOHs27dOoqKigDIz8/XHJOfn8/27dsBKCoqIiUlhdzc3KB9fMcbmT59Og888ECCP40QQghhbPGmAwC88N1WAP7x/lp65Gdq9jGbwGZJenVJvUnmR0tqsDNhwgT/4/79+zNs2DCOOeYY5s6dy9ChQwEwmUyaYxRFCdqmF2mfKVOmcOedd/qfl5aW0qFDh3g+ghBCCBEzRVGocGhrS88cUMisS49LUouat0YVQmZkZNC/f39+++03fx2PPkOzf/9+f7anoKCAmpoaiouLQ+5jxG63k52drfkSQgghGooClDtcmm02S/g/5EX8GlWw43A42LBhA23btqVLly4UFBSwYMEC/+s1NTUsWrSI4cOHAzBo0CBsNptmn71797J27Vr/PkIIIURjoyhQoQt2UppxF1ayJbUb6+677+bss8+mY8eO7N+/n4cffpjS0lKuvvpqTCYTkydPZtq0aXTv3p3u3bszbdo00tPTueyyywDIycnhuuuu46677qJly5bk5eVx9913079/f//oLCGEEKKxUVCCgx2rBDv1JanBzq5du7j00ks5ePAgrVu3ZujQofzwww906tQJgHvuuYeqqipuvvlmiouLGTJkCF988QVZWVn+czz++ONYrVYuuugiqqqqGD16NHPmzMFisSTrYwkhhBBhKYpRN5YEO/XFpCiKkuxGJFtpaSk5OTmUlJRI/Y4QQoiE6/y3jzXP27VIo6i0GrcncAu+aeQx/PX0Xg3dtCYt2vu3hJFCCCFEPTLKKThcbk2gA5LZqU9yZYUQQoh6pA9qAEqrXUHbUmQ0Vr2RYEcIIYSoR26DzE6NyxO0TQqU649cWSGEEKIeeYLjGkPSjVV/5MoKIYQQ9cgos2NEgp36I1dWCCGEqEdGNTtGpBur/siVFUIIIepRtDO8yAzK9UeurBBCCFGPos3sNNturOJtcGhzUpvQTK+sEEII0ThEW7PTbLuxljwOs46HRf9KWhOa6ZUVQgghGofoR2M1w3l2aiph7bvexx2HJq0ZEuwIIYQQ9eiozuwsnQWOUmjRETqdlLRmNMMrK4QQQjQenmhHYzW3mp1tS+Cbad7Hw/8M5uR9vmZ2ZYUQQojGxXM0zrPjrIZP/+p9fPxVcOL1SW1OM7qyQgghROMTbjSW1Ryo02lW3VhfPQT71kJaHoy+P9mtkWBHCCGEqE/hMjtpNov/cbPJ7LhqYNWr3scTn4SMVsltDxLsCCGEEPXKHWY0VmpKINhpNjU7vy+EqmLIaAM9z0h2awAJdoQQQoh6Fa4bK10d7DSHbiy3E758wPt4wEVgtoTfv4E0gysrhBBCNF7hurHsqgCnWcyzs24+HPgV0lvCKXcluzV+EuwIIYQQ9ShcsGNVDce2NYfMzg//9X4fchOk5yW3LSrN4MoKIYQQjVfY0ViqbE6Tr9nZ/yvs+RnMVhh8TbJbo9HEr6wQQgjRuIXL7JhNzSjYWfOW9/sxoxvFCCy1Jn5lhRBCiMYt3GgsdZ2O2dyEa3ZKdsGPT3sfD7w4uW0xIMGOEEIIUY/CdWOpMztNlqLAx3dDTTl0GAJ9zkt2i4JIsCOEEELUIyVMN9YJnb1FvHkZKQ3VnMT76A7Y9Km3VuesJ5K6BlYo1mQ3QAghhGjOwq163jIzhVX/HEuqrXHMRxOz4u2w4kXv4zP+H+T3SW57QpBgRwghhKhH4bqxLGYTLdKbcFZn9Tzv986nNLoRWGqNL9ckhBBCNCPhRmNZmnJR8rYlsHiG93G/C5Lblggk2BFCCCHqUbjRWNamHOx892/wuKDbWDjuimS3JiwJdoQQQoh6FL4bq4nehkv3ehf8BJjwf2CxJbc9ETTRqyyEEEI0DeFGYzXZzM7q10HxQMdh0PKYZLcmIgl2hBBCiHoUbjRWk6zZURRY9ar3cSPvvvKRYEcIIYSIQ1WNm7eW7+RguSPsfpFGYzU5O3+EQ7+DLQP6nJvs1kRFgh0hhBAiDv9bvJm/vP0LFz39fdj9mt1orGXPe7/3PQ/smcltS5Qk2BFCCCHisHTzIQC2HKwIu1+zGo219VtY86b38eBrk9uWGEiwI4QQQsShX2GO/3G4rixPc+rG+uG/3u+DJkH7QUltSiwk2BFCCCHikJYSuIX+vONIyP3CdWNZm9LQ872/wKbPvY+H3pzctsRIlosQQggh4uByB4KY4oqaoNc9HoW/v7+WX3YdCXmOJpPZKT8Ar5wPihu6nAqteya7RTGRYEcIIYSIQ42qGMcoe7No0wFe+3FH2HM0iWDH7YT5N0DFAWjdGy6cm+wWxawJ5c+EEEKIxkOd2TEqyympcmqed2uTSbsWaZptTSLY+fFp2PwlWNPg/GcgPS/ZLYqZBDtCCCFEHFyeQGbHaOJAky6O6d02m+/+dhpnDyz0b2sSo7FWv+H9Pu4haDsguW2JkwQ7QgghRBycqsxOuCUhfCy1cU2KJXDrbfSZnQObYN8aMFsb/crm4UiwI4QQQsTBpa7ZMejHMutSO+bawCbFGthutTTyYGfdu97vx5zWJLuvfCTYEUIIIeLgjFCzo+/GstRuUGd2GnU3lqLA2ne8j/uen9y21JEEO0IIIUQcnBFGY5nQBjIWf2YncOvVZ38alX3r4OAmsNih1xnJbk2dSLAjhBBCxMHlUWd2Ihcomw2CnUY9qaCvC6v7WEjNCb9vI9eIr7IQQgjReGkzO8Gv63M2gW4sS2BbY63ZUXdh9WvaXVggwY4QQggRF+08O8HRjn6LrzxHm9lppMHOnp+heBvY0qHH6cluTZ1JsCOEEELEQZ3ZMRp57tale3zdWDZVNqfRDj33dWH1OB1SMpLblgSQYEcIIYSIg1Nds2PQj6UPdnzdWOpsTqPM7Hg8sHa+93Ez6MICCXaEEEKIIG6Pworth3G43CH3Uc+zYzSDsksf7NQGNupsjrkxBjubPoXSXZCSBd3GJrs1CSHBjhBCCKEzc8FGLpj9PXe9uTrkPpHWxnKrlpOAQGBjMTfimh23Ez6+2/v4hGvBlprc9iSIBDtCCCGEzjOLtwDw0S97Q+7j9KhrdqLI7Jh8wY5qW2MLdn7/Esr2QEYbGDkl2a1JGAl2hBBCCB1TFJP9RZpUMKhA2eT7rq7ZaUS3YUWBZc95H/e7AGxp4fdvQhrRVRZCCCEah2gSLpG6sdSvQ6AbSx3sNKrEzqrX4PcF3kU/j78q2a1JKAl2hBBCCB39Ug9GNGtjxTAaS911FU0GqcGsfMn7fcTfIL9PctuSYBLsCCGEECp3vLGKKmfoUVg+Lk/4bix9zY4/s9Oo0jm1irfDzh8AExx3ebJbk3CNJtiZPn06JpOJyZMn+7cpisLUqVMpLCwkLS2NkSNHsm7dOs1xDoeD2267jVatWpGRkcHEiRPZtWtXA7deCCFEc6AoCvN/3h3VvrGOxvJldBrdCCyAxTO837ucCtmFyW1LPWgUwc6yZct45plnGDBggGb7jBkzmDlzJk899RTLli2joKCAsWPHUlZW5t9n8uTJzJ8/n3nz5rFkyRLKy8s566yzcLsjR+VCCCGarmcWb+b8/37HvtLqhJ3TaCbkUCIVKIcajdXoVjov3++t1wE47e/JbUs9SXqwU15ezuWXX86zzz5Lbm6uf7uiKDzxxBPcd999nH/++fTr14+5c+dSWVnJa695fyglJSU8//zzPPbYY4wZM4bjjjuOV155hTVr1rBw4cJkfSQhhBANYNonv7JyxxEufeaHhJ3TKGgJJdblInwxzrBjWgLQqyAr9gbWh/Xvg+KBwuOhw4nJbk29SHqwc8stt3DmmWcyZswYzfatW7dSVFTEuHHj/NvsdjsjRoxg6dKlAKxYsQKn06nZp7CwkH79+vn3MeJwOCgtLdV8CSGEaJq2HKwwLBCOhqIobD1Y4Z8nJ9qzeDyKputKH9iAtoAZAt1YOWk21j84no9uOzmuNifc2tp1sJrJ0hBGkhrszJs3j5UrVzJ9+vSg14qKigDIz8/XbM/Pz/e/VlRUREpKiiYjpN/HyPTp08nJyfF/dejQoa4fRQghRANrlWn3P44lI6P21Fe/M+r/fcO0TzbEdB6nrh7HeJ4d45odgPQUK1ZL0vMNULoHdnzvfdzn3KQ2pT4l7Urv3LmT22+/nVdeeYXU1NDTUeuH5SmKEnGoXqR9pkyZQklJif9r586dsTVeCCFEoxJfqAOPLdgEwLPfbvWeJ8oT6efQMZxnR7cxzWaJvYH1bcUcQIH2J0KL5vuHf9KCnRUrVrB//34GDRqE1WrFarWyaNEinnzySaxWqz+jo8/Q7N+/3/9aQUEBNTU1FBcXh9zHiN1uJzs7W/MlhBCi6Yo3s6MXb7BjtFyEvmsr026Nu131Yt17sPhf3scnXJfUptS3pAU7o0ePZs2aNaxatcr/NXjwYC6//HJWrVpF165dKSgoYMGCBf5jampqWLRoEcOHDwdg0KBB2Gw2zT579+5l7dq1/n2EEEI0T+oEfoJiHZQoc0Q1bm0XlVHNjj6zk5naiIKdqiMw/0ZvYfLxV8OAi5PdonqVtCuflZVFv379NNsyMjJo2bKlf/vkyZOZNm0a3bt3p3v37kybNo309HQuu+wyAHJycrjuuuu46667aNmyJXl5edx99930798/qOBZCCFE85KoAEct2jpnV1DNTvA+bl32J6MxZXZ++wJcVZDXFc56XBs5NkON6MoHu+eee6iqquLmm2+muLiYIUOG8MUXX5CVFRiu9/jjj2O1Wrnooouoqqpi9OjRzJkzB4ulEfaNCiGEqBeJ6saK9jzRdGPpMztZjSnY2fCh93vf88Dc/O+XjejKwzfffKN5bjKZmDp1KlOnTg15TGpqKrNmzWLWrFn12zghhBCNli/WOFTu4IPVezjvuHa0SE+J+zyRON2xj8ZqNN1YjnL4rbb8o/fZyW1LA2kkV14IIYSIjaZmp/b7za+u5Meth1m4YR+v/nFozOc0ytDofbpmL/94f61mWzSjsRpNN9Zvn3u7sHI7Q9tjk92aBtFIrrwQQggRP1+Q8uPWwwB89/uhOM8TeZ+bXl0ZtM0dxWisjJRGcsv1TSLY9/xmX6vj0whmNBJCCCHqJs4JlA3OE/9MzHpBa2M1hgVAq0sDXVjNeMZkPQl2hBBCNH0JG3oeH115DmA8HD3pVr0Gbge07A75/SLv30xIsCOEEKLJ882PU9fsSbyZnWhWPU86txOWPO59POzmo6YLCyTYEUII0Qz4Yg27tY63tTjjE8N5dozSPcm0+WsoL4KMNnDsFcluTYOSYEcIIUST58uspNZx/al4kzGGmR13I8rsuF2w7Dnv477ngTX2YflNmQQ7QgghmjxfWBFLZmfF9sP+x77ur0R2YzWamh23E964wjvkHBMce1myW9TgJNgRQgjRJKnjC9/jaDM7LreHC2Z/739uqa1fibtAOcI8O/++5Ng4z5wAa96CTZ+CNRUumguFSWxLkjSSQf9CCCFErALBhG/od7SZHf28OObawzxxZmPCrXr+4qQTGNWrTVznTYg1b3m/n3IX9Dknee1IIsnsCCGESBpFUbj//bU89+2WmI9VxyWxdmPpYxNLHUcmhRuNldT5dcr3w5ZvvI/7/yF57UgyyewIIYRImtW7Spj7/XYA/nhK15iOVWdT/KOx4ixQNtexZseoPsc3GsuazGBn3XugeKDdIO8K50cpyewIIYRImkqHK+5jFc3j2Lqx9EGNL/sS7+Lp4Wp2kprZWfuO93v/C5PXhkZAgh0hhBDJU4c4QB2YeAwKlF3u0PPchOrGSuRyEb5sj9WSpGCn4hDs/NH7+ChZ3TwUCXaEEEIkjakO0Y62Gys4s1PtCh3s6IOaQDdWfG3xHffKD9t5+KP1KIrin2fHYk7Srfa3LwAFCvpDTvvktKGRkJodIYQQSaOuC/Z4FH/QEQ1NN1btkxR1sON0k2k3vs3pY5pAgXLdanb+/t5aAE7vV4Ar2TU7mz7zfu8xITnv34hIZkcIIUTSqMMA/XDwSAx3V22rqnGHPlaX9PHFI/FmdvTdWCVVTn8AlJSaHVcNbP7K+7jH6Q3//o2MBDtCCCGSxqRK7cQ647A6wPB1S6nPUO0MHeyE6sZKVIGyogQKlJOS2dn+HThKvetgFR7X8O/fyEiwI4QQImk03VixZnbUjxXf98DWaqfHv02feQnqxkrwchEeRcFZWzNktSThVrv+fe/3nhMCMyYexeQKCCGESBpNN1bMmR3VY913gCqnG0VRuOh/33Ph098bZoJ8/MtFGDRBfdzKHcWGbdE33aOAozbYSbU18K3W7YINH3of9z23Yd+7kZICZSGEEEmj7sbyhB48ZUjBoBtLFXRUO90crqhh2TZvgHKoooZWmfag/SD8pIIeBSwmWLOrhPP/u9SwLfplJtwexd+NZbfWbSX2mG1fApUHIS0POp/asO/dSElmRwghRNKou7HqUqDse6wOVvTnU2eR9N1a4TI7vozTsm2Hg18k8L7qgOebjfv9j2NZiT0h1r3n/d77bLBITgMk2BFCCNFIuGJM7WgDk+ACZaOJ/rR7B/gLlA2GnvsCqHCTA3oURRNovbVil/9xgwY7jjJY+673cd/zGu59GzkJdoQQQiSNpo6mDt1Y/tMYZHuMBC8X4dseel+zwWKhVtUoLqPMlMVsatgC5VWvgaMEWnaHLiMa7n0bOQl2hBBCJI06uKhLN5bvPNo6Ht3+IY4FdTdWmGUfDIaQq0dxGQVrDd6Ftfp17/cT/ySjsFTkSgghhEgadZ2Lvsg3EqOFQLV1PKHPF8tyEb4gxmh2Z1+w49Z1Y/k0aLBzaDPs+RlMZunC0pFgRwghRNJoMjt1mFQwMM+O8bmDj9U+D7dchC/jFDaz4zHOTDXoSCzf3DpdToXM1g33vk2ABDtCCCGSRh2wxNyNpTmP97s2u6KE7LoK9VZGAVK4ZR98AdDuI1UcLq8Jet3ekHPs+IIdyeoEkWBHCCFE0qiDi5i7sTRZnODRWB5FG/yEm1TQ98yoDeEKlNUrmo/8f98Evd5g3VjF22DvKm8XVq+zGuY9mxAZgC+EEKLB7TxcSYbdGnZenHBC1eMEZW8MZlnWPwbjYMnfrrAFyuHb2WDdWOs/8H7vfDJktGqY92xCJNgRQgjRoPaXVXPKjK8BePGaE/zbY6nZ0cc6gefa7I3HIPujf6w+3qjI2NcuowJla4QRTw2W2fF1YfU5p2Her4mRbiwhhBANasPeMv/jeOfZ0YckRqOxPIoScih6cLDkH7sexBcAWQy7scKvaJ7SEMHOkZ2wezlggl5n1//7NUES7AghhEgadYBTl24sT4hYRRvgGNfvqI8LV6BsEOsYdm2pGdX5JNyG2i6sTsMhK7/+368JkmBHCCFEg1Lf/jU1O7F0Y+mf155H31VlNDzd6PhAzY5RgXLw8T6RMjtG3WIJJ11YEUmwI4QQImlC1dREPs44M6MvUA413Dx0zU7o9zJqX9KDndI9sPNH7+Pe0oUVigQ7QgghkkaJN7MTouZGP/Q8VICjP96jBO+jb5dR6yIHO2FfrrsNH3q/dxgC2YX1/GZNlwQ7QgghGpS6jKUuMyirBWZQ1tblqIOX/37zO/vLqmvfV5/ZCV2g7A92DAKhSDU74ZasSAjpwoqKBDtCiCDTPtnAH+cuj3mSNyFiFXfNjj6zE2If9fY3l+/i+rnLjY8Pk9nx1/PEVbMT9uW6KdsH25d6H/eeWI9v1PTJPDtCiCDPLN4CwLJthxnStWWSWyOas7gnFUSfmdF+9+2jD15W7yoJ2k99PqMm+IIwo8AlqTU7v34IKNBuELToUH/v0wxIZkcIEVJduhWECMWkGo/lcqvn2Yk/s2NUROyt2Qkx07IuWNq0r5w73lhlGJzc/OpKFN2cPT6Rgp167cWSLqyoSbAjhAitAaYIEUc3dUAdS3AdajRV0KSCIU5p9Fbzf97N9kOVQdv3llSz5WCF4TGRZlCut5qdioOwbYn3sXRhRSTBjhAiJJNEO6KeuTzqTEwd5tnxdUOpXlGU0DUzod6rxm08jbPdajYMXJJWs/PrR6B4oO1AyOtST2/SfEiwI4QQImncqimUQ8QZhoLiDqOanRBdT4bHR2AymQyPiTQa65ZR3WJ7o2hJF1ZMJNgRQmio/3qN8O+4EHWmzuzEUqCsj2GMlotQCL3eVuhV0423ezzBxc5gvDioz6xLj+P0fgUhX49b5WHYssj7uM+5iT9/MyTBjhBCQ/3vuakh1vURRzV1nU5MBcr60VgERzseT5jMTojzhmqCfjZmn3CZnY556SFfq5ONn4Dihvz+0PKY+nmPZkaCHSGERoOs5SOOauoY2hVngXI08+QoBvv5hAqsQhc0G2d2wtXsWC319MeCdGHFTIIdIYSGR5PZSV47xNHBHWc3lj7wCCzkqd4WOngJndkJ0Y2lGOeIwmV2Uiz1cIstPwCbv/Y+lmAnahLsCCE01P/YS6wjwqmsccU1F5P69yr+bizj5+GWi1ALtT1UCxSM63nC1exY6yPY+fYx8Dih3WBo3SPx52+mJNgRQmhogh2JdkQIB8sd9Pnn51z49NI6nSfeAuWQo7F0+4Q8Y8janNCFy8bz7IQJdhJd4b/hI/hxtvfxqCmJPXczJ8tFCCE0tP+gS7QjjC1Yvw+AlTuOxHys+ldMPfQ8EQXK+kkFQ2d2jM8bKlP1xfp9zPhsY9B2S5hJBW2JzOwoCnz9iPfxiX+CbmMSd+6jgGR2hBAaUqAs6pv6V0yd2XHF0iWmH3ru8Z07ugLlUKO0QmWX5ny3zXB72MxOIguUd3wP+9eDLR1G3Ze48x4lJNgRQmio/7qWeXZEKHX51dAs/qlaGyum0VghnmsLlJXQ8+bUbtaPplK3R63a6TbcHu7/kYRmdla+5P3e7wJIa5G48x4lJNgRQmhoR2NJtCOM1eVXQx3sxLtcRPDaWMHdWOFqdnzHW3QfJFRmxxkiCAr3/4gtUZmd6hJY95738fFXJeacRxkJdoQQGh7daBYhjNRl3TRtzY46sxPDOfTz7Pi/60ZjhZwl0PtNX3ITKrvkDNG4cEFfpEVCo7b2HXBVQaue0P6ExJzzKCPBjhBCQz8pmxCGVDf5WIefKwnI7AR1YyUqsxPis4SqJwoX9CUks+OqgZ+e9T4+/koZIhknCXaEEBrqtYQksSOiESrrEYr6d0y7EGgsQ8/13Vja7+Dtkg05n44/sxNdsBNKuJqdhHQDL/23tzA5LRcGXlb38x2lkhrszJ49mwEDBpCdnU12djbDhg3j008/9b+uKApTp06lsLCQtLQ0Ro4cybp16zTncDgc3HbbbbRq1YqMjAwmTpzIrl27GvqjCNFsSDeWiIb6Nh5rsKP+rUrYchG137WZSSXs8g8QXKAc04gwwk8qWGeKAqte9z4e9whktKy/92rmkhrstG/fnkcffZTly5ezfPlyTjvtNM455xx/QDNjxgxmzpzJU089xbJlyygoKGDs2LGUlZX5zzF58mTmz5/PvHnzWLJkCeXl5Zx11lm43caV80KI8KQbS8TKFaJ4NxTNaKw4u7HCnTOwLfJyEfpurFjm+gFv0PfDlNHce0avmI6Lyv71cHgzWOzQZ2Liz38USWqwc/bZZ3PGGWfQo0cPevTowSOPPEJmZiY//PADiqLwxBNPcN9993H++efTr18/5s6dS2VlJa+99hoAJSUlPP/88zz22GOMGTOG4447jldeeYU1a9awcOHCZH40IZosTTdAHEsBiKOD+vck5sxOiJqdWDI7waOxgtsVbrkIXxv0mZlYMzsmk4mCnFR6t82O6biorP/A+73baLBnJf78R5FGU7PjdruZN28eFRUVDBs2jK1bt1JUVMS4ceP8+9jtdkaMGMHSpd7pyVesWIHT6dTsU1hYSL9+/fz7GHE4HJSWlmq+hBBe6huOhDoiFHVQ4Iy5QDnwWDPPTh2WizAejRVmrSvfPDtRFiiH4js8YSOv1DZ86P3e++zEn/sok/RgZ82aNWRmZmK327nxxhuZP38+ffr0oaioCID8/HzN/vn5+f7XioqKSElJITc3N+Q+RqZPn05OTo7/q0OHDgn+VEI0XdqanSQ2RDRqLlVhsdMVY4FyiBmU67QQqMForGiWiwiu2Ynts/gO14+8+s9lx8d0niCHNsP+dWC2Qs8JdTuXSH6w07NnT1atWsUPP/zATTfdxNVXX8369ev9r+ur2RVFiVjhHmmfKVOmUFJS4v/auXNn3T6EEM2IR9cNIIQR9SR7sQYI2pod9Wis6M8RcjSWepvBfoHXfN1Y2u3RtMFuDRzkG3quXuH8zAFtOXNA28gnCmf9+97vXU71jsQSdZL0hUBTUlLo1q0bAIMHD2bZsmX8+9//5q9//Svgzd60bRv4pdm/f78/21NQUEBNTQ3FxcWa7M7+/fsZPnx4yPe02+3Y7fb6+DhCNHn6tYWEMOJSRQU1rhi7sdTnSdQ8O7Vb1OdYuH4fs7/ZbHi8J2Q3VuRoR50NMvu7sQLb9OeMy4baep3eUpicCEnP7OgpioLD4aBLly4UFBSwYMEC/2s1NTUsWrTIH8gMGjQIm82m2Wfv3r2sXbs2bLAjhAjNLd1YwsCK7cXc//5aSqudgH4Bz/gLlN2JGnoeKNrx+21/ecQ2xFOgrAlmah+r18HSd43F7MgO2PMzmMzQ66y6nUsASc7s3HvvvUyYMIEOHTpQVlbGvHnz+Oabb/jss88wmUxMnjyZadOm0b17d7p37860adNIT0/nssu8Eyvl5ORw3XXXcdddd9GyZUvy8vK4++676d+/P2PGjEnmRxOiyVLft2QFdOFzwWzvoA+3ovDwuf01I7BinlQwxGisWEZCRdONFf547/egoedR/M6bDTI76pqdOid2fIXJHYdDZus6nkxAkoOdffv2ceWVV7J3715ycnIYMGAAn332GWPHjgXgnnvuoaqqiptvvpni4mKGDBnCF198QVZWYAje448/jtVq5aKLLqKqqorRo0czZ84cLBZLsj6WEE2azLMjwvm9NluizsKEWiQzFM1orAQVKHv8BcrRnSPkpIJRfBarJtgxyOzUNdrxDTmXUVgJk9Rg5/nnnw/7uslkYurUqUydOjXkPqmpqcyaNYtZs2YluHVCHJ3085QIoeb7lVAHOLFndgKP1bU/iRl6Htvx5jpmdnyPrKrMTp26scqKYOeP3scS7CRM3MHOkSNH+Omnn9i/fz8eXX/tVVfJEvRCNFVSsyPC8f1KqIOUusygHP/Qc+NoJ9rf2bosF6HO3PgCH/U8O3VaE+vXjwAF2g2GnHbxn0doxBXsfPjhh1x++eVUVFSQlZWl+cGaTCYJdoRowvRrCwmh5sv2qYOCmhgzO+pfK02Bch0yO77f22jrzHx76QuU9QGXxWwKKpw2ytwkZIVzCHRhyfIQCRXXaKy77rqLa6+9lrKyMo4cOUJxcbH/6/Dhw4luoxCiAam7rmIcZCOOAoFurMRndhKxEGi08ZLv91wfo+gzO0b1N+q5eXzdYOp5duJeZqXiEGxb4n0sQ84TKq5gZ/fu3fz5z38mPT090e0RQiSZZlLB5DVDNFKBbqzE1OzEuxBoqLWxouUfjaXL0ugDLqNVICym4JFX6qLlWDJUGr9+CIobCvpDXpf4ziEMxRXsjB8/nuXLlye6LUKIRkD9V6kUKAs9o26smBcCRZ3ZUc+gHP/vm++c0Y/G8n7XFyjr22C05pXx0HNVZife/2/Wzfd+73t+fMeLkOKq2TnzzDP5y1/+wvr16+nfvz82m03z+sSJkn4ToqlS/1Uqi54LPd/vhGZtrNosz7srd/HUV7/zzFWD6dYmM+I5QLcQaEzLRRifM+rRWBgXKAdldgxKcTSZndrxWOrzxNWNVXEQti72Pu57XuzHi7DiCnauv/56AB588MGg10wmE263u26tEkIkjfYmItGO0DLqxvIFPne+uRqAv7+3hnl/Ghb6HKFGY8W0XITxFMrRj8byfg8KdnQnMCpGVm8zGngV1x8JGz4AxQOFx0kXVj2IK9jRDzUXQjQfsuq5CKv2l8KpWRtLe0+I1B0VclLBOozG+sf76+hTmB39aCzfchG6aEVfbK1/HfRrYwW/Hlc31tp3vd8lq1MvGt3aWEKI5FLfp6QbS+gFurGMszMAdmv4GewTMhrLYNulz/4Y86SC1ogFyvFkdmL8H6dsH2z/zvu4z7mxHSuiEnews2jRIs4++2y6detG9+7dmThxIt9++20i2yaESAJNgbJ0Ywkd3++EZm0sXWbHbg1/awk1GiuWGMEooKhxeWKeVDDSQqCGQ89NETI7sXZ++Lqw2g2C3E4xHiyiEVew88orrzBmzBjS09P585//zK233kpaWhqjR4/mtddeS3QbhRANSLqxRDi+3wnN0HNdgJBqC5/ZCbXqeV26sVSvxHS8Pphx6yKV+Gp2YvwfZ9173u8yCqvexFWz88gjjzBjxgzuuOMO/7bbb7+dmTNn8tBDD/lXJRdCND3abiyJdoSW7/fDHWboeaTMTiJqdkIFNXVdLiKa2ZK1wU4da3aO7FR1YZ0T/XEiJnFldrZs2cLZZwcvUDZx4kS2bt1a50YJIZJHAhwRji8r4/SoZ1DWBTsRMjvamp3AsbF0/4T6NY3191ffjRVVsKMZeh4spvmCfnwaUKDLqdCiQ/THiZjEFex06NCBL7/8Mmj7l19+SYcO8sMSoinzxFlDIY4u2hmUFU3XVMTMjupxvJnEUHtGewZ/ZkcXreiHnhvOsxNxNFaUjXA74edXvI+H3RblQSIecXVj3XXXXfz5z39m1apVDB8+HJPJxJIlS5gzZw7//ve/E91GIUQDkm4sEY7vd0JToOz2+CcWhMg1O6F+rxJRsxP92lje7/FkdoxmUFaL+nNsWwLVRyC9FXQbHd0xIi5xBTs33XQTBQUFPPbYY7z55psA9O7dmzfeeINzzpE+RyGaMilQFuEYDT13uj1UOQOTycZSs2N07ujaEapmJ7qTRLtchOE8O6pNdSpQ/vUj7/deZ4A5fIAo6iauYAfgvPPO47zzZPIjIZob9T/UktkRev61sXSrnlfVBIId/dw1oc6hl5DMTrTH45tUUN8G7fO4CpSjqT3yeODXT7yPe50VxQGiLmRSQSGEhiazk8R2iMbJv1yEKiqo0WV2ImVoQr1ep+Ui9A2MdHztfibDEuMAw26sCAXKUX2OPSuhbA+kZEKXEZH3F3USdWYnLy+PTZs20apVK3Jzcw2jWZ/Dhw8npHFCiIan+atUoh2hYzTPjsutUFnj8j+PdLMPWbMTy2R8dQyYfIX4Bouaa9TbchHfzvR+7zEebKmR9xd1EnWw8/jjj5OVleV/HC7YEUI0XdKNJcLxd2N5tAXK1arMTqS6mUQMG6/raCzffpHuZZEKlI0Ojzj0fO07sPFjMFlgxF8jNVUkQNTBztVXX+1/PGnSpPpoixCiEVDfbyTUEXq+3wn16Ksat4fKmui7seq1ZifGSQUj/dlutFyENURmZ0zvfBZu2Md1J3cNfcLqEvj4Lu/jk++A1j2ja7Cok7gKlC0WC3v37qVNmzaa7YcOHaJNmza43e4QRwohGjv1PCOS2BF6nigKlCN3Y8W2PVw79KJdz80/9DxCZseom0szqaDq8KevOJ49R6rp2DI99Al//B9UFUOrHjBySlRtFXUXV4FyqKjc4XCQkpJSpwYJIZJLurFEOL5fCadmUsHYCpRDBSQJ6caKukC5NrMTIbVjNYh2zCFGY1kt5vCBjtsJy573Pj71L2CJe0C0iFFMV/rJJ58EvD/c5557jszMTP9rbrebxYsX06tXr8S2UAjRoDxHaTfWk1/+xr7Sah4+t5/UJIahKN5AoUY9qaBHm9mJVLMTMrMTQ2on1HvEWrMTObMTfrmICKPstTZ8COVFkNEa+pwbw4GirmIKdh5//HHA+0v29NNPY7EEJkFKSUmhc+fOPP3004ltoRCiQWluIkdRZmfmgk0AXDG0E73bZtf7+y3edIDc9BT6t8+p9/dKJH2gA+B06TM7cY7GiuHXLXRmJ9pJBaPbT7+cBOgyOxGrfnxv6IHF//I+HnwtWKUXpCHFFOz4FvkcNWoU7777Lrm5ufXSKCFE8mhXoU5iQ5JEfdOuLzsPV3LVCz8BsO3RM+v9/RJJQduFBd6RWZWazE4UJzEQU7dpopaLiJTZMRx6rn49uvdjw/uwfz3Yc2DoTVEeJBIlrpqdr7/+WgIdIZopTTdWDDefGpeHD1fv4UCZox5aVb8UTVF2/Ud4O4sr6/096ouieH/Wak63ohl6HnlSwVBLPYQ+5vvNh/hl15HAviGinWh/er42RuqxjNSNFVWPp7MavnrE+3joTZAm98+GFnd11K5du/jggw/YsWMHNTU1mtdmzpxZ54YJIZJDUSJndhwuN3ardi2f2d9s5vGFmyjMSWXplKa1qKH6c1Y7Y5nZ7uijoBgEO/qh5/HV7ISan+ZAmYNLn/0BCGTCQk1AGG2wGmq5CD2joeehCpRD+uohOPSbt1ZHsjpJEVew8+WXXzJx4kS6dOnCxo0b6devH9u2bUNRFI4//vhEt1EI0YAiLRfx/eZDXPrsD/xlfE9uGdXNv/3zdUUA7Cmpru8mJpz6M1/+3I9MPbsPk07qksQWNV4eRbviOQSPxkr0pIL7SgO/U4qiYDKZ6j6poD+zE2FSQYOiHUuE5SI0ti2B7//jfTzxKUhrEWULRSLF1Y01ZcoU7rrrLtauXUtqairvvPMOO3fuZMSIEVx44YWJbqMQogGp72NGN6375q8B4F+fb9Rsb8oDmPQZhakfrq/X94u6qLURUhRw6DI7wfPshD9HXQqUfT+rkKOxop1U0BPd0HOjzE6k5SL8aiph/k2AAsdfBT1Pj65xIuHiCnY2bNjgn1HZarVSVVVFZmYmDz74IP/3f/+X0AYKIRqWJrNzlBQoJ/NzxjLcunEI7saqcXtimlQwdKAS+Vr4Jr2s61WLduh5pFXPw66tte5dKNkB2e1h/LQ4WikSJa5gJyMjA4fDW4RYWFjI5s2b/a8dPHgwMS0TQiSFplj3KJlpJ5mTJza1iRuNurFcboXKmCYVNOaOJtjxZ3Yi7hpWtMtFRFoINGSWTlFg+QvexydcB/aseJopEiSump2hQ4fy3Xff0adPH84880zuuusu1qxZw7vvvsvQoUMT3UYhRAPSjsYy2KHp9sCEFM1Ntr40tcSOep6dNJuFKqfbuxBoTJMKhujGiuJiBLoc63bhoh16bjFICZijGY219h3YvQKsqXDs5XG2UiRKXMHOzJkzKS8vB2Dq1KmUl5fzxhtv0K1bN//Eg0KIpkk/z47Ho/DQx+sZ0D6H845rH/K4plyzoyRxAFZTy+woBIaeZ9itVDnduDwKlU6Xf5/I3Vjxb/f9ftY1SIx2uYhI3ViGBc4rX4ZP/uJ9fPKdkJUfdztFYsQc7Ljdbnbu3MmAAQMASE9P57///W/CGyaESA59N9bXG/fz4nfbADjvuPYhEztNuei2oTM76vtjUwh2NNMReBRVsGPhoPfvXsqq1cFO+POFXgg01Nw5ge2uBHVj+Q6PNBorUjdWUCy05m344Fbv425jvSubi6SLuWbHYrEwfvx4jhw5Ug/NEUIkm74b61BFTeidm4lkBhyh5pZpTPTrpfm6sdJTAn8vl1Y5VfvHV6AcKujUZBt9wU4du7GirdkxyuxourHUZziyEz6+0/v4xD/Bpa/LshCNRFwFyv3792fLli2JbosQohHQjsZSmnC+JnrJLVBO2ltHTXN9VDMoZ6QEJpYsVWV2Il3O0PPsGG9XBzuJyOwoipL45SKK1sBzY6C6BNoNgvHTwWKLv5EioeIKdh555BHuvvtuPvroI/bu3UtpaanmSwjRdLk1wU70xzXlmp1Qs/E2hIZYnqKu9BNN+oKdNFWwo631iq9AOWTGR3Vu/2is8E0OS1GiXy7CuGZHdes0AY4yeONK74rmuZ3hgufAEvcCBaIexPXTOP1078RIEydO1PR3+ma2dLvrfyE9IUT9UN9vPEpwTUNU0+M3MY21G2vTvjJSrRY6tkxvwBYF0/5OKP6h53arGZvFFLQwaPw1O8bbDYOdOvzMvD9v7/ERl4swXBsr8NhsMsHCqVC8FXI6wPVfQ3pe3G0T9SOuYOfrr79OdDuEEI2Eevjv0TLPTrx1M74/8Ooi1Fsfqaxh3OOLgeSvjK6faNJXs5NiNWM1m3Hq/sCNWLMT4vcq1M/BleBuLO8oQ+/juhYoZxf9CMue8z455ykJdBqpuIKdESNGJLodQohGQl+grP+nPvRorKYrnhvnnW+uYv2eUj649WRSrLFVBKiDgVCBwa7iKlX76h5U1YW2QDkwGivF4s3sqGqTvfvEOfTcd6z+sxp1kdUlEFdq/4PI3VhWowJl1baOKx/1Phg0CbqOjLtNon7FFewsXrw47OunnnpqXI0RQiSfvkD5aBDP0PN3V+4GYPGmA4zpE9s8KuoaoWi60DyKtuukoWmDs0Bmx2YxYzOYdS9SDVS4z2z0WTWZHXciCpQDAVzEAmXDbizvtn6mLWQeXA1mG4z6e/wNEvUurmBn5MiRQdvUkbjU7AjRdOmLUaNOKDThWp661OzEc6w+eFAUhV92ldCtTSYZdqvBPgqWJObONJMuqkZjpVhDBDsxZnYKc1LZU1LtP1b/Wd2q6Mmf2alTN5YS/dBzg99rXwB0vfUT74a+50Jm6/gbJOpdXKOxiouLNV/79+/ns88+44QTTuCLL75IdBuFEA3o6FwItGE/qCaQ8Sh8sHoP5/znOy58+nvVPoH9kz0XjzYAVjTBjtUg5RTrquftcwMF2EafVb0UlysBo7E8gfrkKIaeB2+zmEx0MhVxlrn25zX8z3VojWgIcWV2cnJygraNHTsWu93OHXfcwYoVK+rcMCFEcqjvNR5FCUrYhLo3NN28jvZmGqt4brr60U1vr9gFwPq9pfxh9lLaZNu5/pSumn2SSZ+J8o3GSrGYNb8Pt4w6hv98vTnmmp12uWmwzfg1AJcqs+PL8tQlQFXUmZ0Iv7hG3VhWM9xpfRuLSaG43Uhy2w6Iuy2iYSR0IoDWrVuzcePGRJ5SCNHAFF03VqjXmpOGDibU76fPZCzfXgzAmN75qv0bpl2h6ANgdWanpDJQndwxL92/Tzj64uK2Oama8+tph57XnqOOo7F8h0cq/DYaet5v7QyOsSwFYE+/m8iNvymigcQV7Pzyyy+a54qisHfvXh599FEGDhyYkIYJIZJDfWPxjsYK/GOf7JtufWnobiL9YqtGvt54wHD/ZFB0XZsO1Wgs9czJvsn2IrVWX8CclxFYUsGoWFw79Lw2s1OX0ViKEphUMMK++pqdvqatdN38MgDTnJcyOv+EuNshGk5cwc6xxx6LyWQK+itv6NChvPDCCwlpmBAiObRDz7X/jyf7pltfYs0S6G/+sdJfY6PswtLfDwb2T3rNjvZ5tdM7CMWmG3LvS4LEWrOTlRq4FRmtQK9dG6t2v7pmdmpPEGlSQXU3Vi6lPJfyGCY8fOQewjPusxkdfzNEA4or2Nm6davmudlspnXr1qSmpoY4QgjRVIQbjRWue6IJD8YKyiZEugFqd4/9rqsOlkINez+imrymoVdl19P/3Ktqg50Uiz7Y8V64iDU7uudZqYE1pCJ1YwUyO/FTr40VeVJB73dfoNPWdJiKrC7cd+C6qI4XjUPMwY7H4+HLL7/k3XffZdu2bZhMJrp06cIf/vAHrrzySvnBC9HEKWEyOx5F0a7yrNKU/8/X32CN6jTU4l0/LPB+qschiqOjXWvK6fbwzOItnNytFQM7tIi9MVEIDnYCNTs+aTaLP+CNddVz33D7UMcaTipY55qdKDM7JhNZVPJ2ygMcY94LwKZB/6TkM3v8DRANLqah54qiMHHiRP74xz+ye/du+vfvT9++fdm+fTuTJk3ivPPOq692CiEaSLh6kmbaixV08400HLmu3Xn6OXQiBYrhJumbu3Qb//p8I+f857s6tSkcfWBRXROc2WmRbvNft8iTCmqfZ9oDgVLEmh3fpIJ1rdnxtTHMz9qMh5Gr7mRN6h85xryXMiWNyTU3U9L25LjfWyRHTJmdOXPmsHjxYr788ktGjRqlee2rr77i3HPP5aWXXuKqq65KaCOFEA0n3Dw7bk/wUPTmQD/0PFJmR5P9iuP9olkuQi1cN9Yvu0riaEFs9G10uLzBjnqOnR75WYFgJ8bMTnqKFYvJhEvVvaTm1gw9V2rfI/r260Wb2bnI8g2d9n8JwAElh0k1f2Wd0pkLIqWDRKMTU2bn9ddf59577w0KdABOO+00/va3v/Hqq68mrHFCiIannwNG3TW9/VBFyOOachd2UDdWpMxOHWto9PPWRLp04QqUfYFHfdK/vW80lsVs4oVJgzmleyv+74IB/sAh0uXRny8jxRo2UFJndvzXvi7z7BAYjRUqi5dGNXdZ3wLgPfdwRjpmsk7pDET+/RCNT0zBzi+//MLpp58e8vUJEyawevXqOjdKCJE84f4qn/jUd/xaVNaArWkY+mDCaCI5zf51rdlRZZLcnii6scK8iS/wqE/6TIzvPW0WM6f1yufl64ZQkJPqD3gjZXb0r6fb1fU+wfu73cHzEtUl3FSPxgp17a+xfEZrUwll6e35i/NGKkjzv6b+/Wiuc081NzEFO4cPHyY/P/SCd/n5+RQXF9e5UUKI5NHOs6McFf+Y62+wkbqx6joUPNbFVsPVCDmc9R/sBGV2akdj6a+T7+nmA+Wc89QSPltbFNX5NZkdo+UiDCZhrFOBsifQXRac2VH4P+sz3GN7E4C1PW7Fqav4kLxO0xNTsON2u7FaQ5f5WCwWXC5XyNeFEI2fdrbco2N9LH23VMRgR1OzE8/Qc9V7RxE4hdulIbqxQmd2tNfJl9kprnSyelcJN75ivHSQPrOTajP7r3nkoee+YKcuBcqq99H9qAeZNnGx9RsAfvF0YWe7M4KOV2d2mnL37dEk5tFYkyZN4vzzzzf8uvbaa2N68+nTp3PCCSeQlZVFmzZtOPfcc4OWm1AUhalTp1JYWEhaWhojR45k3bp1mn0cDge33XYbrVq1IiMjg4kTJ7Jr166Y2iKE8NIuF6FEVUALTfuv3ZhrdkKMWFuwfh/n//c7th0MXdsE2uDKW7MTfbeZnroba39Ztf9xcUUNFz39PS99vy3suaOhD7aq/Jkd40kFI55Pl4wymUxhu7E0NTsJ6MZSVCGqOrPTgjL+ZnsdgLWezlxWcx9msyXoeKlPbnpiCnauvvpq2rRpQ05OjuFXmzZtYhqJtWjRIm655RZ++OEHFixYgMvlYty4cVRUBP6hmDFjBjNnzuSpp55i2bJlFBQUMHbsWMrKAnUDkydPZv78+cybN48lS5ZQXl7OWWedhdtd/3/xCNHcuDTdWNGPemnKf+DqswSRR2OpghXVBbr+peWs3HGEu98KX7uY0G4sVbAzdNqXbDlQDsDUD9fx07bD/PP9daEOjZo+2KqsHXpuC+rGiu6XwCgbFq5A2W0Q7NR1NJZ6uYiFd45gav4SvrP/mRPMm6hQ7NzuvIVy0kMENk34l/0oFdPQ8xdffDGhb/7ZZ58Fnb9NmzasWLGCU089FUVReOKJJ7jvvvs4//zzAZg7dy75+fm89tpr3HDDDZSUlPD888/z8ssvM2bMGABeeeUVOnTowMKFCxk/fnxC2yxEc6deYdqjhM8qNBf6oeeR7tlGNSRqhytrwh6vPiSakV3hMztu1X6w+UAFXVtnRl0vE41Q768PCqMNeI0CFf9SEwYvunQFyofKHTz00fro3szw/QO1aDnlv9Pt/YfoVrIcTLDB05H7nNeyWWlX267gDyWZnaYnpsxOfSsp8c4XkZeXB3iXpSgqKmLcuHH+fex2OyNGjGDpUu+KsytWrMDpdGr2KSwspF+/fv59hBDRc7rVN5vwBcrNpXhZfzOPOBQ8xmBFT9F1Y0USbpK+al2BssPl5ucdxWFHaZVUOXnp+20cLHdEfnNC121ZQywXEfl8wScM1OwE769fJf6xBZuiep9w7+9d5NbD8av+AbuXA/Bv13mcUTON1aae/n2NPpLJZMJa296eBVl1aotoGHGtjVUfFEXhzjvv5OSTT6Zfv34AFBV5/zLRjwDLz89n+/bt/n1SUlLIzc0N2sd3vJ7D4cDhCPxPXlpamrDPIURT51SlOSJ1Y3kU8NWohlpGoinQZxP0wcWWA+XcO38Nt47qzsndW2n2NxyZFWmeGd3xka5cuIDKtyinT43Lw//7IlD72LVVRtAxd7+1mgXr9/Huyt28d8tJEd49dGbHGm83lsHpwg1bd+kmFSxVrRsWD0XxdqWdY15KXvEvAKw6aTaPf5kDQOtMO0Wl1Zp2qZlN8MvUcVQ7PeSk2YJeF41Po8ns3Hrrrfzyyy+8/vrrQa/pf9lCrRIc7T7Tp0/X1Bp16NAh/oYL0cyouww8SvgC5eayCrr+Y+gzD3+e9zM/bDnMFc//WLu/wSR3MVAnz6LpJoxlnh2Hy8PhivCLiC5Yvw+AVTuPRHxv7/sbb7da9MFOVKcz/DyBFdMjj8aKVFMV+f3B7K7xFyMz+n4OtQ+sX946K7DuldFbmTCRnmIlLyOlTu0QDadRBDu33XYbH3zwAV9//TXt27f3by8oKAAIytDs37/fn+0pKCigpqYmaH4f9T56U6ZMoaSkxP+1c+fORH4cIZq02DI7zSXY0WV2dB+rqKRa89wdKbMTQezdWKF3qtEFOzUuDy538PIK8ap2uvnTS8sNX7PqRmNFOwxb3aR/X3IsQNh1tfQBeLQZJLVOpiJmWP/HvdZXafX9w9x36G8UmIqpSs2HoTdrzqkNdoLfqykX4x+tkhrsKIrCrbfeyrvvvstXX31Fly5dNK936dKFgoICFixY4N9WU1PDokWLGD58OACDBg3CZrNp9tm7dy9r167176Nnt9vJzs7WfAkhvNTBjnqmWSOaIKEJ3wCCg53wAYL6Zu0yCCYihRf6GpSIBdExBCwOl9twqHa8nl60mf1lxrU9oSYVjMTXouevHsw5x2oLgSNmdtyxBzstKeEF27+4yLqIP1k/puXqp+lV4x2ltq3bVWBL1fz+ts4Mn9kRTU9Sa3ZuueUWXnvtNd5//32ysrL8GZycnBzS0tIwmUxMnjyZadOm0b17d7p37860adNIT0/nsssu8+973XXXcdddd9GyZUvy8vK4++676d+/v390lhAiepqh5yhhswrqm5D6nuDxKBGXXGhMImV2wu0fTzChmZQwqm6s6M9d4/Josj2xtk9RFModLrJSvbUovi4vI/pJBaP9mfs+szpo8SWJDIMdXbdhLL9aLSjjU/sU2piOALDS042ebXPYWuxkeWUBbY+5jN5AeXVgQtxWWYHuKZk0sHlIarAze/ZsAEaOHKnZ/uKLLzJp0iQA7rnnHqqqqrj55pspLi5myJAhfPHFF2RlBSrgH3/8caxWKxdddBFVVVWMHj2aOXPmYLEETwYlhAhP3WVApG6sEAN+PIqCuQmlevRDz/U3XP39N9Kq5ZECmFhrfmLpLnS4PEEFvbH4+3trefXHHbx3y0kc26EF6/aEHsARTWbHKPA1mr04kNkJPoc2U+WJumZnsOlXXkj5f2SbKqlSUviT806+9Qzgw7NP5oEP17G8tJinbekAHFKNTEtR3Tvi6TITjU9Sg51o/qIxmUxMnTqVqVOnhtwnNTWVWbNmMWvWrAS2ToijU42mGytCgXKI15pa3XKkbiz9x9FOchfH+wXNwBz9jM2hzuPjrdnRFvRG498Lf+NwhYNXf9wBwJ1vrKJTy/Swx9gskWt2HC4PaSnaPzyN1qUK242l+zyRMkitKOFm6/tcblmI3eTN2NzgvINvPQP87+F7H18TWmelGp7L6K2aSanaUaXRDD0XQjQO6uJWhfD/sGu6sVQ3haZWuOwLGrq2ymDLwYqgIEL/h5n6aTyfNdZurFBBZZUzeJZ4h8ujrbtSvdnOw5Ws3nXE4Bg3jy/Uzl2z5WAFWyIsexGc2TEKdtxBwY7HH+yoj/V+/3bTAVKtFvq3z/G/pg7YPJ7w3VhWXLya8gg9zd4lg5a4+/J/rktZo3RVvb/iD+pTrN6A7fR+BfxlfE8Gd8rlhy2Hw34m0fRIsCOE0FBnBTQLJhoIdaNucsFObXN9N+9IzTdavkAt1gLlSNTX+f1Vu1m4YT//+sMAw4kDvd1YxpmdU2Z8bXj+g+XhZ3wOxRbF2lj6SQ8h8HnUczP5goonv/qdJ7/6nW2Pnll7vBu3qlvO5VHCrl12meVLepp3cUjJYrLzFr719EefOVMIrBZvrw12LGYTt4zqBsCPWwPBjtFbxbP4q0guCXaEEBrB3Vih921u3Vi+GYEjdWNFClYiBUv6leUjj8YKPL593ioA+rfLZuLAdkH7OlxuTWYnmpqgAyFGW0ViCZpnxzizoxfoxgp9rKIo/FpUxhlPfqvNpHmC51DLpJJR5lVUYudB21wAHnf9wd9tFfz+ij9QtFvD13b63ivFYtb8vyGaFgl2hBAa2tFY4bM0IWtJmlxmx9te3+ii4EkGjfcH+H7zIX4/sJL7z+oT9fuFWkg0FKPrvOdIddAcO+DrxootcxRvsKOfQdkoaDPK7BgVKOuPrXF7mLlgU9C1d3kUUm2BjFJX0x5m2WbR17zdv+2gks1b7hEh2+1RAvMT+TI7aur39H1Em8VEjawt3WRJsCOE8PN4FO3NUYkwz47qPqbuklCa2B/AvoDD6l+fKdJoqsDjn7Z5uzyMAo9QNJMSRhEYGv0MHC43Ne7gu2+V7o7s9njXNwsX9ES7RpZeNMtFGGV2fJ9Zvb++/sfh8pCeEpx1catmUG5vOsD7Kf8gy1QFQKmSzmpPV172nI6D0LMbezyKv11GwY7RZ7JZzfiinSYWywsk2BFCqDh1Y8lj6cZS3+fiWUIhmXyJEN+MwMFDz7XPjQKHnYcrA/tHqOkI6saK2L7g81U7PdS4grdXOFxB2zwKHAmznlTc3VhRBDuGNTsG++uPdThDBzu1lVU8YJ1DlqmKDZ6O3OiczHbFO+t+isUMaN/3mpM6s3jTATYfqPDW7ETdjYXqnKKpkmBHCOGnmWOHyAXK6pt+XUcoJZMvmLGG6sbS7W/0+WKZfE4dPEUTGBoFV97MTnAgUVETHOy4PQrFFaGLkOMJdqxmU9BnNroE4Wp2TJqaneDj0mxWzHgoNB2in2krN1k/oPPGUmw4udnuJMdUSY1i4Vbnbf5AB2onKNS9raJoh7f7gx1bcBCjbVdtZkcV7DSt324BEuwIIVT0wU6kzI76pq/OZjS1YMcXTFhCdWPpa3YMeqxiGaCsuW5K5LE9RpfTm9kxCHYcwcGF26NwONHBjiX4E4cajaXuegJ1N5bq2NonZjycal5N1pefc8menfzRvopCU2B0FL5YrvbYp1znsVnRFmqHGi7u2+50B7r1ImVsfMfUdfFRkVwS7Agh/PTdWN55dsLU7IRY0LKJxTr+tltVQ88VJXjUT2B/o8xO4HEso7F8NTXhGGV2qp1uw2Cn3KAby62ED3YOV8Y+9Fy/CCgYZ7d+2nqI2+f9zF3jenLdyd71DwOZncD+aTgYZ17GX63zOMa8F9ZCDmiiyLmusRR3nsCY8o/YeMjJa67TWKH0DHrPUEPTfZurVfMTGWV21PKzvetkFeSksqO2qzKauZFE4yLBjhDCz6nrFomtGyu2EUCNiX7oOXg/u+/mqP80da1J0hYoR75eRu/ncHkMC5Qra4MdkykQVLjdStiAptKg6ysS48xO8LZnv90KwEMfrfcHO/7Zi307bV3McwcuIz3FW2hcrGTi7HM++0qq+GS7hcWeAbQ2FfON51gmpLblQMsTebVoR8i2Gc2wrA5e735ztX+7UWZHfbk7tczgg1tPorBFGvfNX8PuI1X0b5cT8r1F4yTBjhDCL7hmJ0I3lio20hbdNrFgx6Mdeg7a9b2CZ1CuW2ZH0XVjuWPY38eb2TEoUK4dMZRqtfhnWHYrCofDTBxYGceYav1ILIhh1XP/PDsmqCqGt64hXalit9KSL9yDedz1B/43eDQ/bj3E7C2/1R7UGfAOPY8UHBoOJ1e1r6w2ILSaTZoAN5QB7VsA8L8rB4fN+InGS4IdIYRfUGaHCJmdEAtiNrFYR9WNZQ7aZqSuc8vF3o0VvK3aaVyg7JNiNVPtcqMo4PJ4DLu3AP77ze9Bw9WjYVTDEu3SCppVz799DCoPssvakdHlD/qHjDtc7qDgG7zXSz0X1MD2Odx7Rm/eXL6Ld1Z6l4hItQWPsFIXKPukhBh2Hu5jSKDTNMlYOiGEn9MgsxPt2lhNObPjC9qsBkW0EOVorBhKlPW1TtF2Y6mDolAFyj42i8lfu+LxGK+jBTDjs43sLamOuu0+xjU70R3rUeAE0690+OZ2WPokAG/mXKOZG8fh8gTVkIH3WqknYnR5FIZ0bUm73LSw7RjRo3XQ9khz7IjmQzI7Qgg/fWbHo4Sf4Vdz02/CNTv6oecQOlO1v7Sa++avrdP76QPDSNdLURSeWbyZNFXGwuEKH+xYzWYsZhMuj4LL44krexNOtDU7PuosSqea33g95SHMv9d+7lP/ws9bhgOH/PtUO6PL7Pj2ybQHro2+Fa9dP4RhXVvy9KLNIdskmjcJdoQQfi7dTdfbjRV6f0/IzE6CG1bPAkPPjbux1IPD7377F8MZh2Pp3dBcN0/47BnAruIqnlm8RbPN4XRTYzCHjY/VYgoMpfdAdQwzPEcjmm6sNhQzyLyJU82/sD2lG/y0C091Kfd5XsZsrv3QF70MfSZi2vaT5liHy2MYBFY53ZrtvuxPpt2maUerTLv/5zT8mFYA3HJaN/7z1e8s314cxycWTZkEO0IIv+DRWEqcNTtNK9rRDz33bjP+DL/sOmK4Pd55djxK5NFdRsPGq13uoG5HtRSL2d+NVR+ZHaOskrV0B3+yfEgZ6Rxv+o3zLEuwmmr383wNn3hrJwaYoVKxY7lxEfa2vQHQJ4q8a3wF3uO207ox66vfOVDmoFVmoLvLt0+GKrODCVpn2YOC0lE92zCie2u63vtJ7bHG1+/yIR157tstnNG/bVTXQjR+EuwIIfyMhp5HuzZWQ2Z2FEVhze4SOrXMICfNFvmAKM4H2q4Z9fpe6ktg1LUS6nx6v+8v44rnfqKoNFAj446iG8sosHC6lbAFylaLyb8quUdRNHPLJELQMhDOKlrMv4x7bb9pNm/xFJBlqsSFlbbtu+Jww7xdubzGBD6vDXTAaLmIQDfWnWN7cN5x7Zj11e/sK62mR36mf79AN1bgdmbCG+xs2BvcbvWwdGeIbFfLTDs//3OcTCTYjEiwI4TwCxp6TvRrYzXkPDvf/naQq174icKcVJZOGV3n8/naq14SwBMia+Uymj4ZfbeXsb+/t1YT6ICvCDz89dIHoT7hloCwmtWZHSVkgXK8HOrzuRzw1iSsh72Bzi6lFbuU1vzLeZFm0r8t153Bb3tLuX/WEtpk2TXn049yUhco261mWtfu73B5NJkuX3YmQx3smEz0Lcxm8aYDYT+DUQG0jwQ6zYsEO0IIv1gnFfTVnhyuqGHLgYrA9nruxvpsXREAe+IYRWTEF6gYLWmgKIqmuyPU/TGaAM9hkElwe5SI3VihApV9YZZ5sKlqdtye+DM7T19xPDe+sjJoe7WvXsjlgDevhk2foVhTubTybn7w9DE8V7XLTWntgqT6jFzQ2liqzI7VYibVZqFFuo0jlU72HAn83F3+mh1tZufPp3WnqKSa0/sVEEq4bkDRvEgpuhDCT/+Pf8RVzz0KlTUujn9ogaZLpb5LdmwJ/qvbF9hYTCZ/obHvc+uDmFDZgGgCPKNr6R16Hv64SoP1rgD2lYYO9mwWsybYiTezYzeYswZqf1dcNfDWJNj0KVhTqTj/1ZCBDkBVjZuSEMGOPpPy5Fe/+7Ngvlqq/KxUAE12zGWY2YG0FAuPX3ws4/uGDnaa2qhBET8JdoQQfvoumkg1O25FYe7S7UHb6zuzYzGY46Uu1AtTqlfGBqO5h8Kfw/d47e6SoGyK0bWMphvLaCVz8A6DD8Wqz+zEWaBsNFOylwKfT4GNn4A1FS59HU/XEWHPtW5Pachgx2jSw5+2ehcA9dVStcm2B+1jVKAcy5xH4ugg3VhCCL9Yu7EURTEcnVTXtaMisRnM8VIX/mDHbMJsArdqW7giYDV1lmBfqYOzZi1hTO98nrt6sH+70WVxR7H8QajlHPaVhuvG0mZ24h16rs64dDbt5WLLNxxj2kNnUxEs2+194cK5cMxpmEPM0uxz1Qs/cdmQjgBk64KdPUeqQh5nqw1u87NTg17z/c5mpwbOFyo4FEcvCXaEEH5BWYxIBcoe47qH+h56rqmt8SiGCz/GwhfPmE2m2kLZwOcOVRysZ/SRF27Yp3luFDhGM/Q81FIP4bqmrOZAZucPT38f9vzh+Iq2R5p/Zrbt36SZVEXRFjuMfRB6ng5EtzbWOyu8SzroMzvqOhw9X2ZHXZfjc+6x7QDtEhEllc7IDRFHFQl2hBB+LyzZqnkecdVzRTEcnVTfpRDqxRurXW7SU+r2T5kvOLPUZnYgUHwdzVBziC6bZbTLkt8PaIq7jVRGyJgYsarm2akLCx6utCzgIduLAPzo6cUi9wAyTNXccttUaHmMf99o1sbyFWnrMzvhAjdf0Ga3absvJw4s5KFz+wXtXxbH9RLNmwQ7QggA1u4u4deiMs02T4S1sTwexTAYCLfERCKob+KVNXUPdnzdSCZVzY4SY2YnmmJXo8Bx077yiMdVxFFvk6LqxopXL9MOun/xHx6yfQfAek8nJrnuo8rjzaLcogp09LLs1rBBRyzzI/myS3artlj6gkHtNYXJ0Tq9bwGfrStiZM/WMR8rmiYJdoQQAIZDk73LRYTJ7HiMMzv1XbOjfs9Khxsyw+wcBf/Qc5Nq8cwYa3Ya26TR6gLlWGRTznXWzzjV/AvHmX+HPd7Zjt9zn8T/3GdhSbFDiCBGndnJTrOFDXZaZqRonv/9zN48/PEGbhjRlf8t0i6N4SuSTtVldkIXT4f3rwsHMLp3G8b1CT1SSzQvEuwIIYJkp1oprXbVdmOF3s+tGGd26vvGr55RuNJpfEMtqXJy1Qs/cWb/Av50augMBKhHY6mHnsfWjRXd0POGi4isZnNUwUDX1hm0a5FGe+d2snZ+xVXWBbQ3HQTArZio7jSSS7efzS8ub2Bw2bGFvPbjDnrmZwWdS/12aSnGQ9Z9cnXBzh9P6crFJ3QgK9VG+xZp/OP9df7XQmV29MFcRoolqixYVqqNCwd3iLifaD4k2BFCANqg5u9n9uGed36JuDaWoig4DaKh+r6pqyfnqwgxB81z325h9c4jrN55JOpgx2QKLCcQa4FydN1YUZ0qIWwWU1SF2/8b4aT7xv/Czs+htmdpp9KGOa6xLPIM5H9nX851u0u4fd4q/nxaN24a2Y0B7XI4rXeboHOpMzsZKRY+uPUk9hypMpyUUJ/ZAW8QAvhnS/bxFSjbreEzOy3SU6ioCT2qSxy9JNgRQgCBG/4xrTNoleW9ESlEmGfHAy6DYOCqF37ivGPb8fB5/epcT2NE3bUUaoHLIzGMyFHPoKyfZyfamYdDBXiKoviXQkjUKLVeBVnM+9NQjn1wQch9bJZwmR2FM9LW8WS7r7B+9EPtFhNfuwey1NOXr1LHsMXhDTisZhPnHNuOkT3akJPuDUYuObGj4VnV9cnpKVYGtG/BgPYtOKZ1Bpt1Rdj6zI5amu53xl+grAt29JmdnDQbu8MMYRdHLwl2hBCAriuHQJFumOWDcHs8Ibux3v15N3kZKfz9rNAz6sZL3Y0Vak4Vhyt8kLJpXxmLNx3gqmGd/QXVZpNqNJY/2KlbZqfa6fF36SQq4WUxm2iRnsIp3Vvx7W8HDfexWkxB6021ppgTzBsZa1nBecp3sAsw2+DYS3nLfj73fF0JQNe0DKioqD2PN8DwBTrhqN8vXdWN9cofh/Dlhv08+eVv7K9d4iIvPUywo5u12d+NZQvfjdUiijaKo5MEO0IIIHAjNptMoLrhh+uSqnZ6wi6m+PuByCON4qEOdkJldoxWClcb9/hiwNslpp5U0HfD9n2saDM7oWp7KmpcgWAnqjNF5svYzLnmREqrnBz3UHCGJ9Xk5uSKhYywbqIFFRQpuVxv/YRskzegcWPGMuQGGH4b5LSjauk2wFsnk6UaKRVvEXC6apRU25w0rhjaieeXbIXaYCdcTU+67jVrlJkdCXZEKBLsCCEAXd2Kavh1uDqTcocrbAGvOuBYuaOY3/aVcfEJxl0gsVDX0YTK7Ki7uuYu3cblQzpq5ufxt2t7sf+maTYRNBor2jWlQo3aUo8WS1Qtk+9zWMwmw+6gQaaNXL/uXvKqtgX9K1+qpLPS050P0yfy2IS7VedUjaRKDRwU7/D1DINgJtpz6QMhX2Yn1aYPgrQ/zz+degyfrClibJ/8WJoqjgIS7AghgEBQ4+3G8m0Lv25ThcMVtjBXHeyc/9+lALRrkc7J3VvVqa2xZnbu/2AdiqIw6aQuQfu5FQWT4v3EFlU3lqJ4156KNrMTKthRB2OJCnaMgoYcyvmDZTHHmX9jvHk5tio3R0w5LHQNxIyHFpSz2DOAV9xjcGGlqy1Dc7xNFTioMyu2ONchM8rcRDvJob4bK1SBsv46HNuhBcv/PobcMF1k4ugkwY4QAlCvD6UtNA13g66ocYUdrWT02uYD5XUPdtyRR2M5dN1Yq3eVAPDtbwc0a025PQpmk3rouffDv7NyF3OWbgu68YYS6jJVqoKdRNXsaLqWjuzkcdt/GG9eTropsFbWrnYTuK3sSn7eH9g11Wb2F5TrAwVF1cmmLiq3xLkOWYZBYXrbFqls3FdmsLdWvN1YAK0ygxcLFUKCHSGElyqzE303lhtXmB30AUddrdh+mEc//ZV1e0r92yqdLg5X1JCTZtPc/PQ1Oya8Mztf+fxPmu3quiTv0HPv9jlLtwHRd2OFsrekGofLjd1qSWiBMooCWxfDu9dznsW7BtdWTz5vuUfyo6cXt51yOSUfbQACo6Ay7Taqnd6ASB9QqH+O6qxMvDU7Rpmdh87px5/n/cz1p3SN6Vhfd5V+np142yaOPhLsCCEAdc2OthsrbGbHET6zY9S1U5fh1xfMDl7Q8ucdRzj+oQWc2qM1L117Ytj3rjQIXNweBV8pj3roeaLc+trPdGqZzqK/jIpqLp7IFIZXL4Zn/gJ7VwOw2dOW/7nP4iP3MCrxrgyek54SVDyenWrlYLk32NEvs6BuW6oqqEhkzU6HvHTm33xSxGNTLGbMpkCg7e/GskXO7AhhRIIdIQSgrtnBPxor0nIRsRQo15efth4GYPGmA5rtDoMh40YLano8gRFXVos54cEOwPZD3hFQ0S49YaQ1xQw3r2Oi5XtGH/jZu9GaCgMv5ZzvTqKcdM3+OWm2oJ9NpqrwWL+CuHpfdR13IkZjxcpkMpGeYvWv9h6YQTkxy0WIo48EO0IIQDvPjlk1CV64eXYqHC7DtbF8jIKdeHMbsWaEggILE/6bp5pbUdhZG4x0zEunHmIdwNv+WIO/882LOdPyI33M22lrOuzf7saC5dS7YMiNkNGS8u8+Djo2J82GUxfsqOto1IEPaDM76pmX9XP1RCuWhT6NpNos/p+XL4OjH40lmR0RLQl2hBBAIJgwB6bZqa3ZCd+NFa5mxxdwJGIV9KLS6pj2NwosKg1GbhVX1vgnujumdUbIEUOZdqsuWFJIwUUN0d3UHS5P1MFOD9NOzrD8yGTru5rtv3i6sEnpwOauV/LX0y4Ke47sNFtQF2O4zI568da6ZLduOLUr6/aUMrpX8HISsVAv+mkzG2d2JNgR0ZJgRwgBBLqxTKoRSd7lIrT7PXROX6qcbqZ98itltYuFhuKsvbmHm3gwWpv3V0TeSUVfWGzCZJjZ2VK7jEFBdipZqbaQN/rcDJv/+L6mrcy0zaaneRffuAdyp/MmDpNNIQc52bKGD93DqKqtnfG3p8YdVTfWjZYP+Jttnv/5K67RvOs+heqcLqw/4g2szktvF/E8Nos5aCmPLHvoYEfdJVSXGGLKGb3jP1ilMCeNXcXepR8CQ88lsyPiI8GOEAJQd2OhmmsmuED5ymGd2Xm4kmmf/EpxZU3Yc/pu7up6EN/pNhaVMeOzX7n4hA6M61sQsX2HKhwR91GrMAhsKkNMQAjQrY135r9QSY289BR2Hq6in2kL81IeJtPkzTSNtKzmNdMjvOs+mT9ZP6aVqZQZtmdZwIn84OzOWk9XflR6GwZaan1N25ho+Y4brN4uKY9i4in3OTzu+gMKZoa3bAlHDgHR3+T1i7Sqi5L13ViXnNiRD1bvYWzv/KgXP61PnVqm89M2b9edL9ix6YbB6ycVFCIUCXaEEIBuUkFTYJtRN5bvphmpd8rpVvB4lKBC2Wqnm/FPeJdrKHO4DIOdzQfK+XVvGWf0L8BkMhl2QQV9Bo+C2WzC41GC9jeZvEPlQ+nU0lvgGzqzk0IrSphlm0WmqZql7j485T6Xp21P0Mu8k3vNr2v2H8tPjLV5h7nPcY3D82sll1q+pyWl7FFakmJykUMFrUwlnGReRx/zdv+x/3FN5F+uSzTn65iXztLN3mAn2sJcfWYnXDdWpt3KB7eeDMATCzdFdf761LlVYNJDXzeWvn5IMjsiWhLsCCEAdc1OYDiWgmIY0GTYo5toD7zZHXX3jUdR/N0TAMUVxtmh0Y8tAuDFSScwqlcbw0yNnsPlXXQz1Nw4h8pDZ4da1i67ECpZ0MO6nwdS7qeTeT+7lZbc6JxMKZn8seYu7rS9jQmFT90n8r2nD91Me7ik/SHMe1dxkmUdk6xfwBdfMD1CeY+7++lY+p3Pv17PCHqtICfQLWYNM9Ffz/wsLhjk7ebS/+yywgQ7avUxIi1WvuATtAXTahLsiGhJsCOEAPRrY9Vu8xiPgrJbLdgspqDRPkZq3B7NiC2XR+GIqvsr3IKQAH9/by1v3DA05EzJalVOd8hg54t1Rby9YlfIY1vULjFgdKPPo5Sbdj5Arnk/2z1tmOT8K6W1C179pPTmkpp/aPb/w4TxmAuzufy5Hxnv/onzLN8xrFUlyw6m4MRKV9NediutKCaTQ0oOaTjYpLTnHxc/jsVqhteDR1elqIpzw3XffH7HqSFfU9fs6OfZUWsMQcTQri2B8G1pBM0UTYQEO0IIILDKt3rJBAjdVZVht3Kk0hnxvDUuD05X4CROl0dznNF8OOoAa/eRKs79z3ecf3z7iO/lC3KM1ssqrQ6fGcrN8KZdjIZa/932Crk1e9nmyecPNVM5SE7I87TMSOH6U7uydrd3eYrPPSfyuedEpg/rz5R314Rtw9Qwd+8U1eQ3cU/0pwpw9DMoqzWGzE6rTDvf3jMqaCJBn14FWXEPixdHH6nuEkIAITI7qgLl3m2zWaDKGmSnRjfkusbl0YzGcro9msJmoxFK1boA6GB5TVTdWL7JAaNdvFPNl9nR9xCNMy/jfMsSFEzc5rwtbKADcKi2W65Fuvb6bN5fHrENRjHMraO68d4tJ2nqdMJ1Y6ldf4p24VN111W4Nb9G9GgNhA+IGkKHvHTaZGlHtY3s6W3bP8/uk4wmiSZKMjtCCCAwSspsMvm7SZzuQM3OlAm96J6f5d8/2knjnG6PpkDZ6VEoqVJndoIDkyNVwXU8vmUOMu1Walweehdms3rnEc0+voyOPliKRq5BN9YI82qetD0FwLZuV7Fmbfg1ndRa6Fbe3hRFsGOUqbh7fE8Af6YIoi9Q/tuE3vRrl8Pt81YB2gJl/QR9an0Ks/nijlPJ1wUajcG/LzmOQ+UOurbOTHZTRBMiwY4QAtAOPfdN6OZwunWFywHRBjs1Lo9mKLPTFTmzY9Q9tmGvd7Xse8/ozWVDOlLucNHv/s81+zhctd1YcWR28nTBznjzMmbZniTF5GaB+3iyh94La1dEfT792lC/RbHadzjqbqysKLNqFrOJEzrn+Z+rMzvhgh2AHqrAtjHJSbPVeXZmcfSRYEcIAWgnFfQVDVc53ZogSC3aG45DH+y4PZpgxOH04HJ7sKpu5kbBzo7D3iUdfCPBUq3BvfBVNR5/u2PVwl+zA+eYl/CY7WmsJg8fuYcy2Xkzn2XHlknQZ2n2lsQ2A7SvLYEngYfDaot3o6EubM5KtTG6VxvKHS66tgoe8SVEcyU1O0IIQJfZqZ2p1uVR/COu9Dfv7LTo/laqcXs0o7Zq3IommClzuDhx2pccKAsMCy8x6Mby8a3vZLWYNdkOCNTqGBUoR+IbqTSm8lMet83GavLwlutU/uy8FRfWqIODUbU1JQBPX3F81O8/86KBQdvUyyPsVy2X0b+dtm7o4sEdALhiaMegc2hHcZl4ftIJvHHDsJDDuYVojiTYEUIA2nl21F0cvlmH9ffG7CgzOzO/2MTrP+3wP3e6PUE1OYcranhuyRb/83CjvNJVc/yk6kbqVNWhQNlkMsGGD7m+5N+YTQovucZyj+tP2G02Prj1pKiCgx75mfzn8kCAc3q/tvxhUORRZL0KsjSjzf5z2fG0ykxh7jUn+rdNHNiO/Gw7k8d0D2rLQ+f2480bhnH/2X2Dzq0OCJNdcCxEskg3lhAC0M6grM4o+GYi1t9go+3GWvL7Qc1zp9tDcUVwMLPnSCBz4StgPv+4dhzXKZd/vLfW/5q+7kQ9pLzK6Wbp7wfZXruKuZF//WEAf3n7l9rjzVQ7PfRrl+0de//VIwC85BrLP12TABMr/jGG9NpsUlaqlbLa97v0xI60SLcx+5vN/nOf1K2Vf99AGyP/TamvWzpzQFv/zNE+HVum88OU0YZFzClWMyd2yQva7n1/Cw+d05cat0LLTHvEtgjRHEmwI4QAdEPPzd6Ax+HyBIKdOGt29Jxuj2ZSQZ89RwKzKh+pDXZapKdQmKMdEaQOJvQTEn65YR+fr9sX8r2tZhOtsgI3/JO7teLOsT1pnWWHX96AAxuoMmfw/1wX4SuSUS8+2SLd5g92Hjm3Hwreye+ufsG7LESKQR1Rqur4lhkpOFweyh0uhnTJ48et3rWf9MtpgPHIrHjnlblyWOe4jhOiuZBuLCEEoM3sQGC0jttjXLMTf7Cj+IMZtb2qYOdwuTcYyk230TYnTbNfuLliFm7YH/a9W6Tb/EPMwbsyeJ/CbFqnemCBdxbkHwqvppSM2tdNmgn81J/ZbPa+dnK3Vv5tdotBsKNqY4e8dN64YSiXntiBWZce59+uX8NKCJFYEuwIIQB1zY73ub77RT/0PNpJBfUqHC7DRT2LVAW4+8u8j/OzU2mrz+yoanZaxdgtk51mo29htv/5b765b35+BSoOQIuO7O59rf91dVYGoEWadu4c0Ga8jDI76uxTx7x0+hbmMP38AbTJDnwu/erkQojEkmBHCAGoR2NpMzs+ierG8o260p/Po8CHq/ewYvthikq9+7TJtgfNRJyh6sY6prV2hJQ7QtDQJsuOTZV92XOkCrYuhi/+7t0w7FYKWwaCIf1SBTnpwZ9ZnfEyCnbU9U8d8tKCXgfj9ceEEImT1GBn8eLFnH322RQWFmIymXjvvfc0ryuKwtSpUyksLCQtLY2RI0eybt06zT4Oh4PbbruNVq1akZGRwcSJE9m1K/Rif0IIY+p5diC4i0if2cnPjm923f21wY5RsHTb6z9zwezv2bC31P8e6mBi4sBCTbdStzaxzX3ja/MLkwZjt5p5+lQHvHYxuKqh+3gYdA3tcwOrbesDvhYRAjy7NXi0k7rb7dTurTWvzfjDADJSLMy6NPoh6kKI2CU12KmoqGDgwIE89dRThq/PmDGDmTNn8tRTT7Fs2TIKCgoYO3YsZWWBmUgnT57M/PnzmTdvHkuWLKG8vJyzzjoLtzv2oadCHM30kwfadTd6fW1sfnZ8I3t8I61y04O7hPR8wckzVw7i6mGdmH5+f83rsS4Z4Dvfab3yWf+nlpz6083grIRjToOLXgJrCu1aBLIvJx3TSnN8pGyWUWZnbJ98Lji+Pc9eNZghuskALxrcgV+mjmfYMdFPEiiEiF1SR2NNmDCBCRMmGL6mKApPPPEE9913H+effz4Ac+fOJT8/n9dee40bbriBkpISnn/+eV5++WXGjBkDwCuvvEKHDh1YuHAh48ePb7DPIkRTp+gLlK3ha3YijQzq0iqDrQcrQr5u1CWkZrOYyK3dZ1zfAsb1LTB8j1i08Y3EOrwFy7xLoKYcupwKl7wGNm8glGG3ckr3Vuw8XMnfJvTSHK/vUtPTT3II0DLTzmMGEwb6xLuCuRAieo22Zmfr1q0UFRUxbtw4/za73c6IESNYunQpACtWrMDpdGr2KSwspF+/fv59hBDR8dT2Y9WuAWpQsxPbTTnSZHqRMjttslIjBlSFLdK4a2wPxvXJj6pNrbPsULQGnh8HlYegYABcOg9s2lqal68bwpd3jSQ3Q9vGoRGWadDX+AghGodG+39mUVERAPn52n/E8vPz/a8VFRWRkpJCbm5uyH2MOBwOSktLNV9CHO0i1+wEHzM8TPdL77ZZnN63IGTXT6T6lzZRdpPdNro7j5zX3/C1Mb3baJ53qNkMcyd6R14V9IfL34IU4+yQUcZlQPsWvPrHIXx990jN9lE9W5OXkcLInm2CjhFCJF+jDXZ89H/ZKYoS8a+9SPtMnz6dnJwc/1eHDh0S0lYhmjJ9zY5+6LnR/1NPXHwsZ/Zvy9XDOgW95vbAfy8/nlX/HGv4fi0iZHZ6FWSHfV2tZUaKYXBy44hjWPuAtzu7j2kbA768EqoOQ7tBcPVHkBXcNRbJSd1aBXWfvTDpBH68d7SmGFkI0Xg02mCnoMD7j5A+Q7N//35/tqegoICamhqKi4tD7mNkypQplJSU+L927tyZ4NYL0fQoMQ49B2iTncp/Lj/esMDW5fZgNptC/uERqf7l+I4tomh1bdvMpkA9DvDiNSfw7FWDGdQpl4wUCxe32ck8+zSsjiPQbjBcOR/Soj9/JCaTSTOkXQjRuDTa/zu7dOlCQUEBCxYs8G+rqalh0aJFDB8+HIBBgwZhs9k0++zdu5e1a9f69zFit9vJzs7WfAlxtAs1g7JPuELabm2ygra5Isx5k5cRPrNzfKfcsK/rdVANGT+mVSZj++RjMpkwrXmbR8v/Tjbl0P4EuPJdSM0JcyYhRHOT1JxreXk5v//+u//51q1bWbVqFXl5eXTs2JHJkyczbdo0unfvTvfu3Zk2bRrp6elcdtllAOTk5HDddddx11130bJlS/Ly8rj77rvp37+/f3SWECI66rWxIDjYyQjTRdOtTSZzrz2RNll2Jvz7WwBcnvBLIISa/bhVpp1WmSl0jXGk1VXDO/HTNu9aU/46ofUfwPw/YVI80OccOPdpSEkPcxYhRHOU1GBn+fLljBo1yv/8zjvvBODqq69mzpw53HPPPVRVVXHzzTdTXFzMkCFD+OKLL8jKCvwV+fjjj2O1Wrnooouoqqpi9OjRzJkzB4sleHIvIURowZkdbeI3Uj3KiB7aCfO6tQ7O9qi1yjTO7Cz56yisYbq/Qjmzf1vWjijFZjF5h7X//iW8fS0oHjjuCjh7VmComRDiqJLUYGfkyJFhp0k3mUxMnTqVqVOnhtwnNTWVWbNmMWvWrHpooRBHj+C1sQJ/MFhrV0GPxmeTT2Hn4Sr6tw/fVdQyRGZHn1GKlslkCsyLs/17eOMK8Dihz7lw9pMS6AhxFJP/+4UQQPDaWOqFPjNTrVFnWnoVZDM2inlvWmam8M5NwxjZszXdY1z2IaxVr8FL53hnRu42Bs5/FsyS6RXiaCbBjhACCJ5nRz0/jnrxzXj8eXT3oG1ZdiuDOuUx55oT6RxjfY4hRYEvH4T3bgK3A3qeCRe9DNbIy1IIIZo3CXaEEEDwPDvqoeFZqXULdu4c24PV94+jR34gg6POFPkmJ4x76QRXDcy/Ab59zPv81Hvg4lekGFkIASS5ZkcI0Xjo18ZSZ3YSMVleTpotaFZmnyuHdiI9xRJxOQZD1SXwxpWwdRGYLDDxSW9BshBC1JJgRwgBhM/shBt2HotxfQtYvaskaI4dq8XMxSd0jP2EJbvh1Qth/zpIyYSL5nrrdIQQQkWCHSEEoJ5nxxvtqJdzsCZoZe7rT+lKdpqNU7u3qvvJDmyEl86Fsj2Qme9d56pt6NXFhRBHLwl2hBBA8Dw7GSmBLqdIsyFHK8Vq5sqhwetoxaysCF65wBvotOoJV7wNLeLIDAkhjgoS7AghgOB5dtQFxJFmQ25Q1aXw6h+gZCfkHQPXfgbpeclulRCiEZPRWEIIAHzxjNmgy8rlTkxmp85cNfDmlVC0BjJaezM6EugIISKQYEcIAQSvjaXmTlA3Vp0oCnxwK2z5BmwZcNmbkNc12a0SQjQBEuwIIYDgmh0IFCaf2CXJ2RNFgYX3wy9veIeXX/QStDs+uW0SQjQZUrMjhACCa3YAvrjjVBas38dVwzonp1EAbhd8+hdY/oL3+cRZ0F2GlwshoifBjhACCF4bC6Br60xuGJHAdati5XbCO9fB+vcBE0z4Pzju8uS1RwjRJEmwI4QAgtfGSjq3E96+FjZ8AJYUuOB56DMx2a0SQjRBEuwIIYDgGZSTyu2Et6+BDR96A52LX4Ue45LdKiFEEyXBjhACCF4bK2mqiuGtSd5RVxY7XPIqdB+b3DYJIZo0CXaEEEAjyezs/xXmXQaHN4MtHS56WYqRhRB1JsGOEAIIXhurwa3/AN67CWrKIacDXPo6FPRPTluEEM2KBDtCCMB4np2GeWOPdw6dpU96n3c+BS6cAxkJWCxUCCGQYEcIUctonp1656qB926Ete94nw+7FcZMBYutARshhGjuJNgRQgBJyOyU7/fW5+xaBmYrnPs0DLiwYd5bCHFUkWBHCAGEXxsr4SoPw0vnwv51YM+BP7wghchCiHojwY4QAmjAzM7hLfDGld5AJzMfrvkUWh5Tv+8phDiqSbAjhABUNTv1uTzwps/h3euhugQyWsNV70ugI4SodxLsCCEA47WxEmrJ47Bwqvdx+xPgwrmQ065+3ksIIVQk2BFCAN4R4FBP8+z8MDsQ6JxwPYyfBtaUxL+PEEIYkGBHCAHU0wzKbhd89ldY9pz3+al/gdP+nsA3EEKIyCTYEUIA9bA2lnqNK0ww5n44aXJizi2EEDGoz1JEobNg/T6mfrAOl9uT7KYIESShmZ2SXfDcWG+gY8uAi1+Bk+9ooHHtQgihJZmdBnT9S8sB6FWQxSUndkxya4TQStjaWDWV8PqlcOg3yG7vXeOq7YAEtFAIIeIjwU4DqKxx8X+f/up/vq/UkcTWCGGstherbt1YjjJ453oo+gXSW8I1n0Bup4S0Twgh4iXBTgOY/c1m5n6/3f/capFUvmh8ApMKxnmC6lJ4aSLs+RnMNrjoZQl0hBCNgtTsNICtBys0zy0NutKiENFR6jrPzndPeAOdtDyY9DF0PilxjRNCiDqQYKcBWHXBjf750ehQuYO1u0uS3QyhUqe1sfauhh+e9j6e+CR0HJK4hgkhRB1JsNMArBbtZa6XSduamDEzF3HWrCVs2leW7KaIWr5JBWPO7BzZCS+dA84KaDsQep6Z+MYJIUQdSLDTAGy6Gp0a19E99HxfaTXFlU4AVu88ktzGCL+4lotwO+Gd67xz6hQe513rql4X1xJCiNjJv0oNwKr7x9/hciepJY3D4k0H/I9TrPIr2FgosRYoVx2B1y6GnT+CPQcunANpufXUOiGEiJ+MxmoA+ptHtdM4s7N40wHunb+GGRcMYHi3Vg3QsuRYveuI/3FZtYtqp5vr5i5j2dZi0lIs5KbbeOS8/gzs0IJMu/yKNpSY5tmpOgJzzoR9a8GaBhc8B7md67V9QggRL/mzugE4dN1W1U5vZqfG5WHmFxtZuaMYgKte+IldxVVc9tyPDd7GhlRe7fI/Lqt28eJ32/ju90PUuD2UVDnZdqiSy5/7kWtfXJbEVh59op5B2eWAeZd7A53MfLjuc+gxrv4bKIQQcZJgpwFUObXdVr5urJe+38aTX/3O+f9dmoxmJU1FTeB6lDucvPfzbsP9ftp22P/4f4s2M+7xRRwqlwkZ64u/GytStLN0FmxfAvZsuOIdb1GyEEI0YhLs1KN3V+7inrdX88mavZrtjtpurKN1JFJlTSCzU17t4mAUAcz0T39l075ynl60uT6bdlSLKrNTVQw/zPY+njADCvrXf8OEEKKOpCCiHi3fXsyby3cFba+uzezYLEdnrFnhCGR2SqtdFFfWhNxXURRNDYk+SyYSxzeDcsiaHWeVd82ryoOQ2wX6X9hwjRNCiDo4Ou+2DSRUca2vQFk9Eqmq5ui5iaszO7uKK/032ScvPY7Zlx+v2bfM4dI8N+G9Ebs9Ck8v2uyvdxJ1F3Ho+ad/hR3fe0deXfIqWORvJSFE0yD/WtWjUMGOr2bH47vLA4cqjp5aFHVmZ9k2b7CSnWpl4sBCSmrn3/G5fu5y2uWmBZ3j3ZW7eLR2cdVtj8okdokQduj5ruWw8iXv44vmQn7fBmuXEELUlWR26lGkzE6ZalTSwXLjrpyPf9nLB6v3JL5xSaTO7PjkZaQAkJNuY+61J/q3/7j1MO+uDBQw+5IO6/aU1m8jj0IhMztl++DVPwAK9LsAjhnV8I0TQog6kMxOPQod7HgzG6XVgSyG0SijwxU13PLaSgBG9WxNVqqtHlrZ8CoMuuxya4MdgBE9WtOnbTbr9wYHNL4bsm/RSpE4IdfG+u7f3sLk/H5w1hMN3i4hhKgryezUo8xUbbDzz7P6AKpgpyqQ4ThQFhzsrNoZqEfZV1pdH01MuKKSap5dvCVkDZLL7TFcLkPdpQeBTI+erwvMrQp2qqVoOSE8/m6s2mjHUQbv3wo//Mf7fMxUSM1OStuEEKIuJNipR/rMTot0b2bGN8mgOrOz43ClZl9FUVixXR3seIOhn3cUc/asJSzdfFCz/6Z9ZZz33+/4aethiitqEhoAuNwebnl1JTMXbIq475R3f+GRTzZwybM/cN5/v+PNZTsBcLo9PPLxei783/eGxxXpgjnftdIrry1YdroCwc6eI1WUVDkN9xfRU9TdWIe3wNMnw88vAyY4+U7oNia5DRRCiDhJN1Y9yggR7PhqdkpVN+hN+8o1+1Y53axSLZK5r7SaxZsOcNULPwFw2bM/su6B8bz+0w4uOL49d765irW7S7nof9+TZrNwUrdWPHf14IR8jh+3Hubj2rmChnbJ41BFDWcPLAza77O1RXy90bvulW+Bzw17SzmlRyueXbyVF77bqtm/VWaKv1YpN702k+PxgLuG3LQQwU5tnZN6uPppjy2ibU4qC+8cEXTNRfT8mR088OpFULwNcjrCebOh88lJbZsQQtSF3BnqUZauGysnzXtDP1juwO1RKFUVKP+49ZBm3wqHm+2HAtmeT9cWsWD9Ps0+/3h/Le+u3M3i3w5ysCxw869yulm4YR9Ot8c/l0+Fw4VbUcgOUffz+boiXliylf934UDW7SlhxmcbqXF7OO+4dnRtneHfz7eURV5GCiep1u/adrCCG19ZEXTeaqeHW1/7OWh181SbmS/vGsnK7cXM+uo3ni78FJ57CA5sBEcJD2Dh+pQ8nFhJNznIpgILHg7sy4fn2jJ5XxVX2sCFBSdWaiqtlLz6Ihl5OWCxgSVF9V332JpivD3osT3867GsDp5ADpebSodbU+eUCL6anbSi5XDoN0jJhD8ugKyChL6PEEI0NAl26pG+GytX1TVz1qwl/i4Z0I7MAm93jbpORx/oAP5RSos3HaBnflZQV9DmA+X0KsimqsbNWbOWUFLl5Ou7R/L7/jKKK5yM6ZPv3/fZxVtYvr2YpxdtZsuBCrYcrADgf4u28MdTugS991e/7uekbq1wuT28vmwnVQYjrHx83XGn9mjtX/G82ukhJ83GqF5tGNXBDP86Q3OMGTcdzQeCztXBvQt27aIPgEX34o7ar4ZitoG1NiCypnof+75b7Jrn1YqVnSVOOrfOxmZLAbPV+5WSAel5kJbn/W7PBnsW2DO9j1MyvedRBVZT3lnDR7/s5ZPbT6ZbmyxqXB7eWL6TQR1z6VMYf02Nr24qe9M73g19zpFARwjRLEiwU4/0XSotM+2YTd7ugg0GI43UxsxchNsT/YijjQZLT5z+xLecOaAtPdpksbU2ePnolz3cN38tAK/9cQjDjmmJomrPh7ph7jVuD1/9uj/o3Mu3F3Oksoa3V+zi4Y83BL933wIKW6RxqMLB+6u857xyaCe++/1g8OeqVGW1bvgWsgrYuGs/97/0KYpiohI7JWSgAP3Tj/DfC3vylzeW43A4SDG5sOH9ys+wcO3QQlZuPcCKrfvITYGCTAvts830bp0Kbie4a2q/nP7vLqcDs8eJ2eN9ze10YFZcmNT7uRyArt0eJ9REVyuUCnQHKIpqd620XO9IqPx+uFv1YMeqYtKVdsxdup0Hz+nLlc//yI9bD9O7bTaf3n5K0OEut4cjVU5sZjNpKRbNZJZqigLdTLvI+vUN74ZjL4ujsUII0fhIsFOP1JmdVpkp5KTZePLS49hdXMXrP+1g26FKHpjYl/s/WBd0bCyBTjgf/7KXjwmszeULdMDbJTWqZ2vuHt/TPxxc3bXWtzCbdXtK+bUoOJBavfMIxz64wPA9rzmpM/ef7Z10bveRKr7+dT8t0lMY2bM1nVqms+VAhfaAqtpC7Nwu0HYAAIWdc/nBsz3o3AdrCinpNJq3qwOT4PmVwr++UD13AZXAflh92TgUFD5dW0SbLDtuj8LYPvnsPFzFhH8vpnt+Fu/cNJz3V+3mzjdXc+uobtw9vqf2/B43K7fuo7i0nHveWI4NFykmF/+7pB+929j57tfd1Diq8NRUM7RTJhlmJ7gcbNy9n9e/34IVN1bcXDOsA/kZltpgqQIqD0PVYVzlhygvLSbbXIW7qgybuzJwfbZ9C9u+xQK8bfduLlvTgrJ9fRi3M4celnzK9qVTsaYEU2o2H2+3Mu747uRkZnDHW2v5cM1+wMTYPvk8e9VgqmrcvL9qNyN6tqZtjnfSxlSliqdsszB5XNBjgtTpCCGaDZMiE5ZQWlpKTk4OJSUlZGcndmht5799DMDxHVvw7s0n+bc7XG4OV9TQNifNv8+fT+vGot8OaupbsuxW+rXLYWyffHLSbNz11moAlvx1FGaTiaLSas2q6RcP7sCPWw+RarMYBilGMu1WTZcaQKtMO2cNaMucpdti+rxPXzGI03q10WQPDpU7sFrM5KTZeHzBJv795W/YrWY2PjzBu8PGT+H1S6DwePjT1/7jfNdFryA7NajLLpLCnFQOltdQ4w4e9h5KVqqVvIwUrGYTXVtn0iE3nReXbg0OsoD/XTmIG17W1ix1yEsjxWJmsy64G9ihBQ+f0w+7zcwPWw7xyZq9/GFQB95ftZtvfwuMsku3mbhpWD67tqzHvXcNvUw76GbaQzfzbtqbtKPxolGjeOub0lJTKXOaqHCbcSkWPOYUahQzaUo1HcwHcKe3wXLTt9KFJYRo9KK9f0tmp4F0yEvXPLdbLf6/qD+67WRW7TzC5UM6MvSYlvxx7nIqazMtZQ4Xr/9pKOCtqSiurGFw5zza53rPV9gijX+c1YeHPlrPqT1a839/GOB/j7eW7+Qvb/8CwIR+BXyxfl9Qxig33UZx7RINZ/Qv4JM13n6WjnlpDD+mpT/YuXJoJ17+ITjTYrOYUBSYNLwz7XPTGN83P2ghyZaZdv/jW0/rRqrNwsierQM7+DI76Xma4wZ1ymXF9mJeuvZEVu08whMLN+FRAsPUJ/Qr4NO1RZzcrRVLfg9/899TEvs8RWXVLn8tlT5g0dMHOgA7D1dpnj931WBufX0lq3ce4eynlmhe+2HL4aDjK50Kjy0uAvKAEZrX0qnmGNMeepl30Nu0g84pJdicZWSbKmlBOe1MB7GatIFdislNCm5wOMgBckyA70dV+7hGseK5YA4WCXSEEM2IZHZomMzOYxcO5IJB7aM65kCZgwtmL2XH4UpG92rD85NOiHjMruJKWmbYSUsJVO2WVjuZ9MJP9CzIYurEvhyuqGHB+n28/P123IrCGf3a8qcRXdmwp5QUq5n+7XJY/NsBZny2kVtP68aZ/dv6h8T3yM9kwfp9PPX17zx5yXEoQIfcNA6W15Bms5ATYl6cqHz/H/j8Xu8q2hc8599c7XRzoMzhDxSLK2rYVFub1DIzhWNaZ7LtUCWd8tK5881VvFdbG9Qq087Vwzqxq9g7/86NI4/B4XRjMpn4eUcx76/aw1kD2/LajzvYVVzFyd1acWyHFnz5636uGNqRqho3Mz7fSI3Lw8SBhZzWqw0v/7CdPUequOD49vyw5RA7Dley32AiyAfP6cvIHm24553VtEhLYUL/Al79cQedW6Yz4w8D+XHLIf75/joO1s6Y7VEUiiudtMxIwWQyUVrtJDvVynEdcynMSeXjNUUMaJ/D6X0LuOcdb+D68Ln9+H7LIT7+ZS+ts+z8ZXxPOrfM4NbXVrK/zFE7pN+BFTc2XFx5QiFV1dUsWLMTq8lNSm2N09n9WlNVVc1Pm/eRmwrje+Ux4uRTadXumPh/lkII0YCivX9LsEP9BjvLth1m1Y4j/PGULkEZj3D2l1bz2k87uPTEjuRnpya0TY3OVw/D4n/BiX+CM/4V1ylKqpy8tHQblw7pSCtVJqk+fb/5EBv2lnKkyonFZCIr1co1J3WO6eccC1/xuNEcR3prd5ew5PeDXHNSZ+xWbwB8qNzBM99uIc1m4dqTu4SchkAIIZqKoy7Y+e9//8u//vUv9u7dS9++fXniiSc45ZTgkSlG6jPYEVH4+C5Y9hyM+CuMujfZrRFCCNFERHv/bhbLRbzxxhtMnjyZ++67j59//plTTjmFCRMmsGNHQ066IuJWWVuvkpab3HYIIYRolppFgfLMmTO57rrr+OMf/wjAE088weeff87s2bOZPn168hpWeRhqyiPvd7Qrq518RoIdIYQQ9aDJBzs1NTWsWLGCv/3tb5rt48aNY+nSpYbHOBwOHI5AcWlpafgJ/uL25YOw4sX6OXdzJMGOEEKIetDkg52DBw/idrvJz8/XbM/Pz6eoyHi62unTp/PAAw/Uf+N8ywiIyHI6QPvIo86EEEKIWDX5YMdHPwJGUZSQo2KmTJnCnXfe6X9eWlpKhw4dEt+oM/4V9+giIYQQQiRGkw92WrVqhcViCcri7N+/Pyjb42O327HbG2Z4shBCCCGSq8mPxkpJSWHQoEEsWKBdp2nBggUMHz48Sa0SQgghRGPR5DM7AHfeeSdXXnklgwcPZtiwYTzzzDPs2LGDG2+8MdlNE0IIIUSSNYtg5+KLL+bQoUM8+OCD7N27l379+vHJJ5/QqVOnZDdNCCGEEEnWbGZQrguZQVkIIYRoeo6qGZSFEEIIIUKRYEcIIYQQzZoEO0IIIYRo1iTYEUIIIUSzJsGOEEIIIZo1CXaEEEII0axJsCOEEEKIZk2CHSGEEEI0axLsCCGEEKJZaxbLRdSVbxLp0tLSJLdECCGEENHy3bcjLQYhwQ5QVlYGQIcOHZLcEiGEEELEqqysjJycnJCvy9pYgMfjYc+ePWRlZWEymRJ23tLSUjp06MDOnTtlza0oyPWKnlyr6Mm1io1cr+jJtYpefV0rRVEoKyujsLAQszl0ZY5kdgCz2Uz79u3r7fzZ2dnyP0IM5HpFT65V9ORaxUauV/TkWkWvPq5VuIyOjxQoCyGEEKJZk2BHCCGEEM2aBDv1yG63c//992O325PdlCZBrlf05FpFT65VbOR6RU+uVfSSfa2kQFkIIYQQzZpkdoQQQgjRrEmwI4QQQohmTYIdIYQQQjRrEuwIIYQQolmTYKce/fe//6VLly6kpqYyaNAgvv3222Q3qcEtXryYs88+m8LCQkwmE++9957mdUVRmDp1KoWFhaSlpTFy5EjWrVun2cfhcHDbbbfRqlUrMjIymDhxIrt27WrAT9Ewpk+fzgknnEBWVhZt2rTh3HPPZePGjZp95Hp5zZ49mwEDBvgnKBs2bBiffvqp/3W5TqFNnz4dk8nE5MmT/dvkegVMnToVk8mk+SooKPC/LtdKa/fu3VxxxRW0bNmS9PR0jj32WFasWOF/vdFcL0XUi3nz5ik2m0159tlnlfXr1yu33367kpGRoWzfvj3ZTWtQn3zyiXLfffcp77zzjgIo8+fP17z+6KOPKllZWco777yjrFmzRrn44ouVtm3bKqWlpf59brzxRqVdu3bKggULlJUrVyqjRo1SBg4cqLhcrgb+NPVr/PjxyosvvqisXbtWWbVqlXLmmWcqHTt2VMrLy/37yPXy+uCDD5SPP/5Y2bhxo7Jx40bl3nvvVWw2m7J27VpFUeQ6hfLTTz8pnTt3VgYMGKDcfvvt/u1yvQLuv/9+pW/fvsrevXv9X/v37/e/Ltcq4PDhw0qnTp2USZMmKT/++KOydetWZeHChcrvv//u36exXC8JdurJiSeeqNx4442abb169VL+9re/JalFyacPdjwej1JQUKA8+uij/m3V1dVKTk6O8vTTTyuKoihHjhxRbDabMm/ePP8+u3fvVsxms/LZZ581WNuTYf/+/QqgLFq0SFEUuV6R5ObmKs8995xcpxDKysqU7t27KwsWLFBGjBjhD3bkemndf//9ysCBAw1fk2ul9de//lU5+eSTQ77emK6XdGPVg5qaGlasWMG4ceM028eNG8fSpUuT1KrGZ+vWrRQVFWmuk91uZ8SIEf7rtGLFCpxOp2afwsJC+vXr1+yvZUlJCQB5eXmAXK9Q3G438+bNo6KigmHDhsl1CuGWW27hzDPPZMyYMZrtcr2C/fbbbxQWFtKlSxcuueQStmzZAsi10vvggw8YPHgwF154IW3atOG4447j2Wef9b/emK6XBDv14ODBg7jdbvLz8zXb8/PzKSoqSlKrGh/ftQh3nYqKikhJSSE3NzfkPs2RoijceeednHzyyfTr1w+Q66W3Zs0aMjMzsdvt3HjjjcyfP58+ffrIdTIwb948Vq5cyfTp04Nek+ulNWTIEF566SU+//xznn32WYqKihg+fDiHDh2Sa6WzZcsWZs+eTffu3fn888+58cYb+fOf/8xLL70ENK7fLVn1vB6ZTCbNc0VRgraJ+K5Tc7+Wt956K7/88gtLliwJek2ul1fPnj1ZtWoVR44c4Z133uHqq69m0aJF/tflOnnt3LmT22+/nS+++ILU1NSQ+8n18powYYL/cf/+/Rk2bBjHHHMMc+fOZejQoYBcKx+Px8PgwYOZNm0aAMcddxzr1q1j9uzZXHXVVf79GsP1ksxOPWjVqhUWiyUoKt2/f39QhHs0841wCHedCgoKqKmpobi4OOQ+zc1tt93GBx98wNdff0379u392+V6aaWkpNCtWzcGDx7M9OnTGThwIP/+97/lOumsWLGC/fv3M2jQIKxWK1arlUWLFvHkk09itVr9n1eul7GMjAz69+/Pb7/9Jr9bOm3btqVPnz6abb1792bHjh1A4/o3S4KdepCSksKgQYNYsGCBZvuCBQsYPnx4klrV+HTp0oWCggLNdaqpqWHRokX+6zRo0CBsNptmn71797J27dpmdy0VReHWW2/l3Xff5auvvqJLly6a1+V6hacoCg6HQ66TzujRo1mzZg2rVq3yfw0ePJjLL7+cVatW0bVrV7leYTgcDjZs2EDbtm3ld0vnpJNOCpoeY9OmTXTq1AloZP9mJazUWWj4hp4///zzyvr165XJkycrGRkZyrZt25LdtAZVVlam/Pzzz8rPP/+sAMrMmTOVn3/+2T8E/9FHH1VycnKUd999V1mzZo1y6aWXGg5LbN++vbJw4UJl5cqVymmnndYsh3HedNNNSk5OjvLNN99ohr1WVlb695Hr5TVlyhRl8eLFytatW5VffvlFuffeexWz2ax88cUXiqLIdYpEPRpLUeR6qd11113KN998o2zZskX54YcflLPOOkvJysry/9st1yrgp59+UqxWq/LII48ov/32m/Lqq68q6enpyiuvvOLfp7FcLwl26tF//vMfpVOnTkpKSopy/PHH+4cQH02+/vprBQj6uvrqqxVF8Q5NvP/++5WCggLFbrcrp556qrJmzRrNOaqqqpRbb71VycvLU9LS0pSzzjpL2bFjRxI+Tf0yuk6A8uKLL/r3kevlde211/r/32rdurUyevRof6CjKHKdItEHO3K9AnzzwNhsNqWwsFA5//zzlXXr1vlfl2ul9eGHHyr9+vVT7Ha70qtXL+WZZ57RvN5YrpdJURQlcXkiIYQQQojGRWp2hBBCCNGsSbAjhBBCiGZNgh0hhBBCNGsS7AghhBCiWZNgRwghhBDNmgQ7QgghhGjWJNgRQgghRLMmwY4Qosnatm0bJpOJVatW1dt7TJo0iXPPPbfezi+EqH8S7AghkmbSpEmYTKagr9NPPz2q4zt06MDevXvp169fPbdUCNGUWZPdACHE0e3000/nxRdf1Gyz2+1RHWuxWPwrKwshRCiS2RFCJJXdbqegoEDzlZubC4DJZGL27NlMmDCBtLQ0unTpwltvveU/Vt+NVVxczOWXX07r1q1JS0uje/fumkBqzZo1nHbaaaSlpdGyZUv+9Kc/UV5e7n/d7XZz55130qJFC1q2bMk999yDfkUdRVGYMWMGXbt2JS0tjYEDB/L222/X4xUSQtSVBDtCiEbtH//4BxdccAGrV6/miiuu4NJLL2XDhg0h912/fj2ffvopGzZsYPbs2bRq1QqAyspKTj/9dHJzc1m2bBlvvfUWCxcu5NZbb/Uf/9hjj/HCCy/w/PPPs2TJEg4fPsz8+fM17/H3v/+dF198kdmzZ7Nu3TruuOMOrrjiChYtWlR/F0EIUTcJXVZUCCFicPXVVysWi0XJyMjQfD344IOKonhXgr/xxhs1xwwZMkS56aabFEVRlK1btyqA8vPPPyuKoihnn322cs011xi+1zPPPKPk5uYq5eXl/m0ff/yxYjablaKiIkVRFKVt27bKo48+6n/d6XQq7du3V8455xxFURSlvLxcSU1NVZYuXao593XXXadceuml8V8IIUS9kpodIURSjRo1itmzZ2u25eXl+R8PGzZM89qwYcNCjr666aabuOCCC1i5ciXjxo3j3HPPZfjw4QBs2LCBgQMHkpGR4d//pJNOwuPxsHHjRlJTU9m7d6/m/axWK4MHD/Z3Za1fv57q6mrGjh2red+amhqOO+642D+8EKJBSLAjhEiqjIwMunXrFtMxJpPJcPuECRPYvn07H3/8MQsXLmT06NHccsst/L//9/9QFCXkcaG263k8HgA+/vhj2rVrp3kt2qJqIUTDk5odIUSj9sMPPwQ979WrV8j9W7duzaRJk3jllVd44okneOaZZwDo06cPq1atoqKiwr/vd999h9lspkePHuTk5NC2bVvN+7lcLlasWOF/3qdPH+x2Ozt27KBbt26arw4dOiTqIwshEkwyO0KIpHI4HBQVFWm2Wa1Wf2HxW2+9xeDBgzn55JN59dVX+emnn3j++ecNz/XPf/6TQYMG0bdvXxwOBx999BG9e/cG4PLLL+f+++/n6quvZurUqRw4cIDbbruNK6+8kvz8fABuv/12Hn30Ubp3707v3r2ZOXMmR44c8Z8/KyuLu+++mzvuuAOPx8PJJ59MaWkpS5cuJTMzk6uvvroerpAQoq4k2BFCJNVnn31G27ZtNdt69uzJr7/+CsADDzzAvHnzuPnmmykoKODVV1+lT58+hudKSUlhypQpbNu2jbS0NE455RTmzZsHQHp6Op9//jm33347J5xwAunp6VxwwQXMnDnTf/xdd93F3r17mTRpEmazmWuvvZbzzjuPkpIS/z4PPfQQbdq0Yfr06WzZsoUWLVpw/PHHc++99yb60gghEsSkKLpJJIQQopEwmUzMnz9flmsQQtSJ1OwIIYQQolmTYEcIIYQQzZrU7AghGi3pZRdCJIJkdoQQQgjRrEmwI4QQQohmTYIdIYQQQjRrEuwIIYQQolmTYEcIIYQQzZoEO0IIIYRo1iTYEUIIIUSzJsGOEEIIIZo1CXaEEEII0az9f8ufKogyeSK/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the diagram that illustrates the overall resulting data flow.\n",
    "\n",
    "![](https://pytorch.org/tutorials/_static/img/reinforcement_learning_diagram.jpg)\n",
    "\n",
    "Actions are chosen either randomly or based on a policy, getting the\n",
    "next step sample from the gym environment. We record the results in the\n",
    "replay memory and also run optimization step on every iteration.\n",
    "Optimization picks a random batch from the replay memory to do training\n",
    "of the new policy. The \\\"older\\\" target\\_net is also used in\n",
    "optimization to compute the expected Q values. A soft update of its\n",
    "weights are performed at every step.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
